{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "\n",
    "PATH_MAIN = '/project/ds5559/group2nba'\n",
    "PATH_STACKED = f'{PATH_MAIN}/stacked_data/'\n",
    "RESULTS_FILE = f'{PATH_MAIN}/results.csv'\n",
    "TARGET = 'Won'\n",
    "FEATURES = 'features'\n",
    "\n",
    "CORES = 2\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('group2nba') \\\n",
    "    .master(f'local[{CORES}]') \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from typing import *\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "FIELDS: Dict[str, T] = {\n",
    "      'Date': StringType\n",
    "    , 'HomeTeam': StringType\n",
    "    , 'AwayTeam': StringType\n",
    "    , 'Team': StringType\n",
    "    , 'Year': IntegerType\n",
    "    , 'Won': IntegerType\n",
    "    \n",
    "    , 'ScoreDiff': IntegerType\n",
    "    , 'Quarter': IntegerType\n",
    "    , 'SecLeftTotal': IntegerType\n",
    "    , 'LogSecLeftTotal': DoubleType\n",
    "    , 'SecLeftTotalInverse': DoubleType\n",
    "    \n",
    "    , 'HasPossession': IntegerType\n",
    "    , 'assist_team_cnt': LongType\n",
    "    , 'assist_opponent_cnt': LongType\n",
    "    , 'turnover_team_cnt': LongType\n",
    "    , 'turnover_opponent_cnt': LongType\n",
    "    , 'block_team_cnt': LongType\n",
    "    , 'block_opponent_cnt': LongType\n",
    "    \n",
    "    , 'foul_team_cnt': LongType\n",
    "    , 'foul_opponent_cnt': LongType\n",
    "    , 'rebound_team_cnt': LongType\n",
    "    , 'rebound_opponent_cnt': LongType\n",
    "    , 'shotOnGoal_team_cnt': LongType\n",
    "    , 'shotOnGoal_opponent_cnt': LongType\n",
    "    , 'freeThrow_team_cnt': LongType\n",
    "    , 'freeThrow_opponent_cnt': LongType\n",
    "    \n",
    "    , 'SecLeftTotalInverseTimesScoreDiff': DoubleType\n",
    "    , 'assist_diff': IntegerType\n",
    "    , 'turnover_diff': IntegerType\n",
    "    , 'block_diff': IntegerType\n",
    "    , 'foul_diff': IntegerType\n",
    "    , 'rebound_diff': IntegerType\n",
    "    , 'shotOnGoal_diff': IntegerType\n",
    "    , 'freeThrow_diff': IntegerType\n",
    "}\n",
    "    \n",
    "schema = StructType([StructField(k, v()) for k, v in FIELDS.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_file(full_file_name):\n",
    "\n",
    "    df = spark.read \\\n",
    "        .format('csv') \\\n",
    "        .option('header', True) \\\n",
    "        .schema(schema) \\\n",
    "        .load(full_file_name)\n",
    "\n",
    "#     display(df.count())\n",
    "#     display(df.printSchema())\n",
    "#     display(df.head(2))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def build_pipeline(list_features):\n",
    "    from pyspark.ml import feature as ft\n",
    "    from pyspark.ml import Pipeline\n",
    "\n",
    "    # Build the Pipeline\n",
    "    print('build the pipeline')\n",
    "\n",
    "    featuresCreator = ft.VectorAssembler(\n",
    "        inputCols=list_features,\n",
    "        outputCol='vectors'\n",
    "    )\n",
    "    \n",
    "    sScaler = ft.StandardScaler(\n",
    "        withMean=True, \n",
    "        withStd=True, \n",
    "        inputCol='vectors', \n",
    "        outputCol='features'\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        stages=[\n",
    "            featuresCreator,\n",
    "            sScaler\n",
    "        ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "def build_cross_validator(model, evaluator, grid):\n",
    "    import pyspark.ml.tuning as tune\n",
    "    \n",
    "    cv = tune.CrossValidator( \n",
    "        estimator=model, \n",
    "        estimatorParamMaps=grid, \n",
    "        evaluator=evaluator\n",
    "    )\n",
    "    \n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class results_cls(NamedTuple):\n",
    "    model_type: str\n",
    "    list_features: list\n",
    "    date_time_run: str\n",
    "    elapsed_time: str\n",
    "    user: str\n",
    "    special_description: str\n",
    "    area_under_roc: float\n",
    "    area_under_pr: float\n",
    "    best_coefficients: list\n",
    "    best_hyperparameters: list\n",
    "        \n",
    "        \n",
    "class model_cls(NamedTuple):\n",
    "    model_type: str\n",
    "    list_features: list\n",
    "    pipeline: object\n",
    "    cross_validator: object\n",
    "    evaluator: object\n",
    "    \n",
    "    \n",
    "def evaluate_cv_model(train_data, test_data, model_obj, user, special_description):\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "    \n",
    "    # Start the Timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fit the Model\n",
    "    print('Build Pipeline')\n",
    "    data_transformer = model_obj.pipeline.fit(train_data)\n",
    "    \n",
    "    print('Fit CV Model')\n",
    "    cvModel = model_obj.cross_validator.fit(data_transformer.transform(train_data))\n",
    "    \n",
    "    print('Transform Test Data')\n",
    "    data_train = data_transformer.transform(test_data)\n",
    "    \n",
    "    print('Evaluate Model Against Test Data')\n",
    "    predictions = cvModel.transform(data_train)\n",
    "    \n",
    "    print('Save Results')\n",
    "    area_under_roc = model_obj.evaluator.evaluate(\n",
    "        predictions, \n",
    "        {model_obj.evaluator.metricName: 'areaUnderROC'}\n",
    "    )\n",
    "    area_under_pr = model_obj.evaluator.evaluate(\n",
    "        predictions, \n",
    "        {model_obj.evaluator.metricName: 'areaUnderPR'}\n",
    "    )\n",
    "    \n",
    "    print(area_under_roc)\n",
    "    print(area_under_pr)\n",
    "    print(model_obj.list_features)\n",
    "    print(cvModel.bestModel.coefficients)\n",
    "    \n",
    "    # End Timer\n",
    "    elapsed_time = round((time.time() - start_time), 2)\n",
    "    \n",
    "    results_obj = results_cls(\n",
    "        model_type = model_obj.model_type,\n",
    "        list_features = model_obj.list_features,\n",
    "        area_under_roc = area_under_roc,\n",
    "        area_under_pr = area_under_pr,\n",
    "        best_coefficients = cvModel.bestModel.coefficients,\n",
    "        best_hyperparameters = cvModel.getEstimatorParamMaps()[ np.argmax(cvModel.avgMetrics) ],\n",
    "        date_time_run=datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\"),\n",
    "        elapsed_time=elapsed_time,\n",
    "        user=user,\n",
    "        special_description=special_description\n",
    "    )\n",
    "    \n",
    "    return predictions, results_obj, cvModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logistic_model_object(pipeline, list_features):\n",
    "    import pyspark.ml.evaluation as ev\n",
    "    from pyspark.ml.classification import LogisticRegression\n",
    "    import pyspark.ml.tuning as tune\n",
    "    \n",
    "    print('Build Logistic Object')\n",
    "\n",
    "    logistic = LogisticRegression(featuresCol = FEATURES, labelCol=TARGET)\n",
    "    \n",
    "    grid = tune.ParamGridBuilder() \\\n",
    "                .addGrid(logistic.maxIter, [2, 10, 50]) \\\n",
    "                .addGrid(logistic.regParam, [0.01, 0.05, 0.3]) \\\n",
    "                .build()\n",
    "\n",
    "    evaluator = ev.BinaryClassificationEvaluator(\n",
    "        metricName = 'areaUnderROC',\n",
    "        rawPredictionCol='rawPrediction', \n",
    "        labelCol=target\n",
    "    )\n",
    "    \n",
    "    cv = tune.CrossValidator( \n",
    "        estimator=logistic, \n",
    "        estimatorParamMaps=grid, \n",
    "        evaluator=evaluator\n",
    "    )\n",
    "    \n",
    "    model_obj = model_cls(\n",
    "        model_type='Logistic',\n",
    "        list_features=list_features,\n",
    "        pipeline=pipeline,\n",
    "        cross_validator=cv,\n",
    "        evaluator=evaluator\n",
    "    )\n",
    "    \n",
    "    return model_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_random_forest_model_object():\n",
    "    import pyspark.ml.evaluation as ev\n",
    "    from pyspark.ml.classification import RandomForestClassifier\n",
    "    import pyspark.ml.tuning as tune\n",
    "    \n",
    "    print('Build Random Forest Object')\n",
    "\n",
    "    random_forest = RandomForestClassifier(featuresCol = FEATURES, labelCol=TARGET)\n",
    "    \n",
    "    grid = tune.ParamGridBuilder() \\\n",
    "        .addGrid(random_forest.maxBins, [2, 3]) \\\n",
    "        .addGrid(random_forest.maxDepth, [3, 5]) \\\n",
    "        .addGrid(random_forest.numTrees, [100, 500]) \\\n",
    "        .build()\n",
    "\n",
    "    evaluator = ev.BinaryClassificationEvaluator(\n",
    "        metricName = 'areaUnderROC',\n",
    "        rawPredictionCol='rawPrediction', \n",
    "        labelCol=target\n",
    "    )\n",
    "    \n",
    "    cv = tune.CrossValidator( \n",
    "        estimator=logistic, \n",
    "        estimatorParamMaps=grid, \n",
    "        evaluator=evaluator\n",
    "    )\n",
    "    \n",
    "    model_obj = model_cls(\n",
    "        model_type='Random Forest',\n",
    "        list_features=list_features,\n",
    "        pipeline=pipeline,\n",
    "        cross_validator=cv,\n",
    "        evaluator=evaluator\n",
    "    )\n",
    "    \n",
    "    return model_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_SVM_model_object():\n",
    "    import pyspark.ml.evaluation as ev\n",
    "    from pyspark.ml.classification import LinearSVC\n",
    "    import pyspark.ml.tuning as tune\n",
    "    \n",
    "    print('Build SVM Model Object')\n",
    "\n",
    "    svm = LinearSVC(featuresCol = FEATURES, labelCol=TARGET)\n",
    "    \n",
    "    grid = tune.ParamGridBuilder() \\\n",
    "                .addGrid(svm.aggregationDepth, [3, 5, 10]) \\\n",
    "                .addGrid(svm.maxIter, [10, 20, 50]) \\\n",
    "                .build()\n",
    "\n",
    "    evaluator = ev.BinaryClassificationEvaluator(\n",
    "        metricName = 'areaUnderROC',\n",
    "        rawPredictionCol='rawPrediction', \n",
    "        labelCol=target\n",
    "    )\n",
    "    \n",
    "    cv = tune.CrossValidator( \n",
    "        estimator=logistic, \n",
    "        estimatorParamMaps=grid, \n",
    "        evaluator=evaluator\n",
    "    )\n",
    "    \n",
    "    model_obj = model_cls(\n",
    "        model_type='Random Forest',\n",
    "        list_features=list_features,\n",
    "        pipeline=pipeline,\n",
    "        cross_validator=cv,\n",
    "        evaluator=evaluator\n",
    "    )\n",
    "    \n",
    "    return model_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-79040d7307f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mfile_str\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_STACKED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mfile_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_str\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_in_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_STACKED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "# Run A Single File\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "file = 'NBA_PBP_2019-20.csv'\n",
    "\n",
    "df = read_in_file(join(PATH_STACKED, file))\n",
    "\n",
    "train_data, test_data = df.randomSplit([0.7, 0.3], seed=123) # LogSecLeftTotal\n",
    "list_features = ['ScoreDiff', 'SecLeftTotalInverse', 'SecLeftTotalInverseTimesScoreDiff']\n",
    "\n",
    "pipeline = build_pipeline(list_features=list_features)\n",
    "\n",
    "model_obj = build_logistic_model_object(pipeline=pipeline, list_features=list_features)\n",
    "\n",
    "predictions, results_obj, cvModel = evaluate_cv_model(\n",
    "    train_data=train_data, \n",
    "    test_data=test_data, \n",
    "    model_obj=model_obj,\n",
    "    user='Peter',\n",
    "    special_description='Test Run 19-20 Only'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_type                                      list_features  \\\n",
      "0   Logistic  [ScoreDiff, SecLeftTotalInverse, SecLeftTotalI...   \n",
      "\n",
      "         date_time_run  elapsed_time   user  special_description  \\\n",
      "0  04/17/2022 23:49:30        306.11  Peter  Test Run 19-20 Only   \n",
      "\n",
      "   area_under_roc  area_under_pr  \\\n",
      "0        0.820472       0.823239   \n",
      "\n",
      "                                   best_coefficients  \\\n",
      "0  [1.4749598979624223, -9.384355132570414e-05, 0...   \n",
      "\n",
      "                                best_hyperparameters  \n",
      "0  {LogisticRegression_b762bb9a2c14__maxIter: 50,...  \n"
     ]
    }
   ],
   "source": [
    "def parse_results_obj(results_obj):\n",
    "    return pd.DataFrame(data=[results_obj])\n",
    "\n",
    "results_df = parse_results_obj(results_obj)\n",
    "print(results_df.head())\n",
    "\n",
    "from os.path import exists\n",
    "file_exists = exists(RESULTS_FILE)\n",
    "if file_exists:\n",
    "    results_df.to_csv(RESULTS_FILE, mode='a', index=False, header=False, sep=\"|\")\n",
    "else:\n",
    "    results_df.to_csv(RESULTS_FILE, mode='w', index=False, header=True, sep=\"\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>list_features</th>\n",
       "      <th>date_time_run</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>user</th>\n",
       "      <th>special_description</th>\n",
       "      <th>area_under_roc</th>\n",
       "      <th>area_under_pr</th>\n",
       "      <th>best_coefficients</th>\n",
       "      <th>best_hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['ScoreDiff', 'SecLeftTotalInverse', 'SecLeftT...</td>\n",
       "      <td>04/17/2022 23:35:57</td>\n",
       "      <td>309.49</td>\n",
       "      <td>Peter</td>\n",
       "      <td>Test Run 19-20 Only</td>\n",
       "      <td>0.820474</td>\n",
       "      <td>0.823240</td>\n",
       "      <td>[1.4749755253169836,-9.339839834844648e-05,0.4...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['ScoreDiff', 'SecLeftTotalInverse', 'SecLeftT...</td>\n",
       "      <td>04/17/2022 23:49:30</td>\n",
       "      <td>306.11</td>\n",
       "      <td>Peter</td>\n",
       "      <td>Test Run 19-20 Only</td>\n",
       "      <td>0.820472</td>\n",
       "      <td>0.823239</td>\n",
       "      <td>[1.4749598979624223,-9.384355132570414e-05,0.4...</td>\n",
       "      <td>{Param(parent='LogisticRegression_b762bb9a2c14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type                                      list_features  \\\n",
       "0   Logistic  ['ScoreDiff', 'SecLeftTotalInverse', 'SecLeftT...   \n",
       "1   Logistic  ['ScoreDiff', 'SecLeftTotalInverse', 'SecLeftT...   \n",
       "\n",
       "         date_time_run  elapsed_time   user  special_description  \\\n",
       "0  04/17/2022 23:35:57        309.49  Peter  Test Run 19-20 Only   \n",
       "1  04/17/2022 23:49:30        306.11  Peter  Test Run 19-20 Only   \n",
       "\n",
       "   area_under_roc  area_under_pr  \\\n",
       "0        0.820474       0.823240   \n",
       "1        0.820472       0.823239   \n",
       "\n",
       "                                   best_coefficients  \\\n",
       "0  [1.4749755253169836,-9.339839834844648e-05,0.4...   \n",
       "1  [1.4749598979624223,-9.384355132570414e-05,0.4...   \n",
       "\n",
       "                                best_hyperparameters  \n",
       "0                                                 []  \n",
       "1  {Param(parent='LogisticRegression_b762bb9a2c14...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_df = pd.read_csv(RESULTS_FILE, sep='|')\n",
    "view_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/ds5559/group2nba/stacked_data/NBA_PBP_2015-16.csv,/project/ds5559/group2nba/stacked_data/NBA_PBP_2016-17.csv,/project/ds5559/group2nba/stacked_data/NBA_PBP_2017-18.csv,/project/ds5559/group2nba/stacked_data/NBA_PBP_2018-29.csv\n"
     ]
    }
   ],
   "source": [
    "train_files = [\n",
    "    'NBA_PBP_2015-16.csv',\n",
    "    'NBA_PBP_2016-17.csv',\n",
    "    'NBA_PBP_2017-18.csv',\n",
    "    'NBA_PBP_2018-29.csv'\n",
    "]\n",
    "\n",
    "validation_file = 'NBA_PBP_2019-20.csv'\n",
    "\n",
    "# Read in all Train_Files\n",
    "\n",
    "file_str = ''\n",
    "for item in train_files:\n",
    "    file_str = file_str + PATH_STACKED + item + ','\n",
    "    \n",
    "file_str = file_str[:-1]\n",
    "print(file_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
