{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "\n",
    "PATH_MAIN = '/project/ds5559/group2nba'\n",
    "PATH_STACKED = f'{PATH_MAIN}/stacked_data/'\n",
    "RESULTS_FILE = f'{PATH_MAIN}/results_expanded_bonus.csv'\n",
    "TARGET = 'Won'\n",
    "FEATURES = 'features'\n",
    "\n",
    "CORES = 4\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('group2nba') \\\n",
    "    .master(f'local[{CORES}]') \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from typing import *\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "FIELDS: Dict[str, T] = {\n",
    "      'Date': StringType\n",
    "    , 'HomeTeam': StringType\n",
    "    , 'AwayTeam': StringType\n",
    "    , 'Team': StringType\n",
    "    , 'Year': IntegerType\n",
    "    , 'Won': IntegerType\n",
    "    \n",
    "    , 'ScoreDiff': IntegerType\n",
    "    , 'Quarter': IntegerType\n",
    "    , 'SecLeftTotal': IntegerType\n",
    "    , 'LogSecLeftTotal': DoubleType\n",
    "    , 'SecLeftTotalInverse': DoubleType\n",
    "    \n",
    "    , 'HasPossession': IntegerType\n",
    "    , 'assist_team_cnt': LongType\n",
    "    , 'assist_opponent_cnt': LongType\n",
    "    , 'turnover_team_cnt': LongType\n",
    "    , 'turnover_opponent_cnt': LongType\n",
    "    , 'block_team_cnt': LongType\n",
    "    , 'block_opponent_cnt': LongType\n",
    "    \n",
    "    , 'foul_team_cnt': LongType\n",
    "    , 'foul_opponent_cnt': LongType\n",
    "    , 'rebound_team_cnt': LongType\n",
    "    , 'rebound_opponent_cnt': LongType\n",
    "    , 'shotOnGoal_team_cnt': LongType\n",
    "    , 'shotOnGoal_opponent_cnt': LongType\n",
    "    , 'freeThrow_team_cnt': LongType\n",
    "    , 'freeThrow_opponent_cnt': LongType\n",
    "    \n",
    "    , 'SecLeftTotalInverseTimesScoreDiff': DoubleType\n",
    "    , 'assist_diff': IntegerType\n",
    "    , 'turnover_diff': IntegerType\n",
    "    , 'block_diff': IntegerType\n",
    "    , 'foul_diff': IntegerType\n",
    "    , 'rebound_diff': IntegerType\n",
    "    , 'shotOnGoal_diff': IntegerType\n",
    "    , 'freeThrow_diff': IntegerType\n",
    "}\n",
    "    \n",
    "schema = StructType([StructField(k, v()) for k, v in FIELDS.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class results_cls:\n",
    "    model_type: str = ''\n",
    "    list_features: list = field(default_factory=list)\n",
    "    date_time_run: str = ''\n",
    "    user: str = ''\n",
    "    special_description: str = ''\n",
    "    cv_elapsed_time: str = ''\n",
    "    cv_area_under_roc: float = 0.0\n",
    "    cv_area_under_pr: float = 0.0\n",
    "    cv_best_coefficients: list = field(default_factory=list)\n",
    "    cv_best_hyperparameters: dict = field(default_factory=dict)\n",
    "    val_elapsed_time: str = ''\n",
    "    val_area_under_roc: float = 0.0\n",
    "    val_area_under_pr: float = 0.0\n",
    "    val_best_coefficients: list = field(default_factory=list)\n",
    "    val_true_positive: int = 0\n",
    "    val_true_negative: int = 0\n",
    "    val_false_positive: int = 0\n",
    "    val_false_negative: int = 0\n",
    "\n",
    "# results = results_cls(date_time_run = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "# results.model_type='SVM'\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    logistic = 'Logistic'\n",
    "    random_forest = 'Random Forest'\n",
    "    svm = 'Support Vector Machine'\n",
    "    \n",
    "    TARGET = 'Won'\n",
    "    FEATURES = 'features'\n",
    "    \n",
    "    def __init__(self, list_features, model_type):\n",
    "        from datetime import datetime\n",
    "        \n",
    "        # Defined in Methods\n",
    "        self.cvModel = None\n",
    "        self.cvPredictions = None\n",
    "        self.valModel = None\n",
    "        self.valPredictions = None\n",
    "        \n",
    "        print('Setup Model')\n",
    "        self.list_features = list_features\n",
    "        self.pipeline = self.build_pipeline()\n",
    "        self.model_type = model_type\n",
    "        self.evaluator = self.build_evaluator()\n",
    "        self.results = results_cls(\n",
    "            model_type = model_type,\n",
    "            list_features = list_features,\n",
    "            date_time_run = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "        )\n",
    "        \n",
    "    def build_pipeline(self):\n",
    "        from pyspark.ml import feature as ft\n",
    "        from pyspark.ml import Pipeline\n",
    "\n",
    "        # Build the Pipeline\n",
    "        print('build the pipeline')\n",
    "\n",
    "        featuresCreator = ft.VectorAssembler(\n",
    "            inputCols=self.list_features,\n",
    "            outputCol='vectors'\n",
    "        )\n",
    "\n",
    "        sScaler = ft.StandardScaler(\n",
    "            withMean=True, \n",
    "            withStd=True, \n",
    "            inputCol='vectors', \n",
    "            outputCol='features'\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline(\n",
    "            stages=[\n",
    "                featuresCreator,\n",
    "                sScaler\n",
    "            ])\n",
    "\n",
    "        return pipeline\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_evaluator():\n",
    "        import pyspark.ml.evaluation as ev\n",
    "\n",
    "        evaluator = ev.BinaryClassificationEvaluator(\n",
    "            metricName = 'areaUnderROC',\n",
    "            rawPredictionCol='rawPrediction', \n",
    "            labelCol=TARGET\n",
    "        )\n",
    "        \n",
    "        return evaluator\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_hyperparams(cvModel):\n",
    "        import re\n",
    "\n",
    "        hyperparams = cvModel.getEstimatorParamMaps()[ np.argmax(cvModel.avgMetrics) ]\n",
    "        hyper_dict = {}\n",
    "\n",
    "        for i in range(len(hyperparams.items())):\n",
    "            hyper_name = re.search(\"name='(.+?)'\", str([x for x in hyperparams.items()][i])).group(1)\n",
    "            hyper_value = [x for x in hyperparams.items()][i][1]\n",
    "\n",
    "            hyper_dict[hyper_name]= hyper_value\n",
    "\n",
    "        print(hyper_dict)\n",
    "    \n",
    "        return hyper_dict\n",
    "    \n",
    "    def evaluate_cv_model(self, test_train_data):\n",
    "        import time\n",
    "\n",
    "        # Start the Timer\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_data, test_data = test_train_data.randomSplit([0.7, 0.3], seed=123) \n",
    "\n",
    "        # Fit the Model\n",
    "        print('Build Data Transformer')\n",
    "        data_transformer = self.pipeline.fit(train_data)\n",
    "\n",
    "        print('Transform Train Data + Fit CV Model')\n",
    "        cvModel = self.cvModel.setParallelism(CORES).fit(data_transformer.transform(train_data))\n",
    "\n",
    "        print('Transform Test Data')\n",
    "        data_train = data_transformer.transform(test_data)\n",
    "\n",
    "        print('Evaluate Model Against Test Data')\n",
    "        self.cv_predictions = cvModel.transform(data_train)\n",
    "\n",
    "        print('Store Results')\n",
    "        \n",
    "        self.results.cv_area_under_roc = self.evaluator.evaluate(\n",
    "            self.cv_predictions, \n",
    "            {self.evaluator.metricName: 'areaUnderROC'}\n",
    "        )\n",
    "        self.results.cv_area_under_pr = self.evaluator.evaluate(\n",
    "            self.cv_predictions, \n",
    "            {self.evaluator.metricName: 'areaUnderPR'}\n",
    "        )\n",
    "\n",
    "        # End Timer\n",
    "        self.results.cv_elapsed_time = round((time.time() - start_time), 2)\n",
    "\n",
    "        # Random Forest doesn't have coefficients\n",
    "        if self.model_type in (self.logistic, self.svm):\n",
    "            self.results.cv_best_coefficients = cvModel.bestModel.coefficients\n",
    "            \n",
    "        self.results.cv_best_hyperparameters = self.extract_hyperparams(cvModel)\n",
    "        \n",
    "    def evaluate_val_model(self, test_train_data, validation_data):\n",
    "        import time\n",
    "\n",
    "        # Start the Timer\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print('Build Data Transformer')\n",
    "        data_transformer = self.pipeline.fit(test_train_data)\n",
    "\n",
    "        print('Transform TestTrain Data + Fit Val Model')\n",
    "        valModel = self.valModel.fit(data_transformer.transform(test_train_data))\n",
    "        \n",
    "        print('Transform Validation Data')\n",
    "        data_train = data_transformer.transform(validation_data)\n",
    "\n",
    "        print('Evaluate Model Against Validation Data')\n",
    "        self.val_predictions = valModel.transform(data_train)\n",
    "        \n",
    "        print('Store Results')\n",
    "        \n",
    "        self.results.val_area_under_roc = self.evaluator.evaluate(\n",
    "            self.val_predictions, \n",
    "            {self.evaluator.metricName: 'areaUnderROC'}\n",
    "        )\n",
    "        self.results.val_area_under_pr = self.evaluator.evaluate(\n",
    "            self.val_predictions, \n",
    "            {self.evaluator.metricName: 'areaUnderPR'}\n",
    "        )\n",
    "\n",
    "        # End Timer\n",
    "        self.results.val_elapsed_time = round((time.time() - start_time), 2)\n",
    "\n",
    "        # Random Forest doesn't have coefficients\n",
    "        if self.model_type in (self.logistic, self.svm):\n",
    "            self.results.val_best_coefficients = valModel.coefficients\n",
    "            \n",
    "        self.results.val_true_positive = test_model.val_predictions.where((F.col('Won') == 1) & (F.col('prediction') == 1)).count()\n",
    "        self.results.val_false_negative = test_model.val_predictions.where((F.col('Won') == 1) & (F.col('prediction') == 0)).count()\n",
    "        self.results.val_false_positive = test_model.val_predictions.where((F.col('Won') == 0) & (F.col('prediction') == 1)).count()\n",
    "        self.results.val_true_negative = test_model.val_predictions.where((F.col('Won') == 0) & (F.col('prediction') == 0)).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMModel(Model):\n",
    "\n",
    "    def __init__(self, list_features):\n",
    "        Model.__init__(\n",
    "            self, \n",
    "            list_features = list_features, \n",
    "            model_type = 'Support Vector Machine'\n",
    "        )\n",
    "        \n",
    "    def build_cv_model(self):\n",
    "        import pyspark.ml.evaluation as ev\n",
    "        from pyspark.ml.classification import LinearSVC\n",
    "        import pyspark.ml.tuning as tune\n",
    "\n",
    "        print('Build CVModel: SVM')\n",
    "\n",
    "        svm = LinearSVC(featuresCol = FEATURES, labelCol=TARGET)\n",
    "\n",
    "        grid = tune.ParamGridBuilder() \\\n",
    "                    .addGrid(svm.aggregationDepth, [3, 5, 10]) \\\n",
    "                    .addGrid(svm.maxIter, [10, 20, 50]) \\\n",
    "                    .build()\n",
    "\n",
    "        self.cvModel = tune.CrossValidator( \n",
    "            estimator=svm, \n",
    "            estimatorParamMaps=grid, \n",
    "            evaluator=self.evaluator,\n",
    "            numFolds=5\n",
    "        )\n",
    "    \n",
    "    def build_val_model(self):\n",
    "        from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "        print('Build ValModel: SVM')\n",
    "\n",
    "        self.valModel = LinearSVC(\n",
    "            featuresCol = FEATURES, \n",
    "            labelCol=TARGET, \n",
    "            **self.results.cv_best_hyperparameters\n",
    "        )\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestModel(Model):\n",
    "\n",
    "    def __init__(self, list_features):\n",
    "        Model.__init__(\n",
    "            self, \n",
    "            list_features = list_features, \n",
    "            model_type = 'Random Forest'\n",
    "        )\n",
    "        \n",
    "    def build_cv_model(self):\n",
    "        from pyspark.ml.classification import RandomForestClassifier\n",
    "        import pyspark.ml.tuning as tune\n",
    "\n",
    "        print('Build CVModel: Random Forest')\n",
    "\n",
    "        random_forest = RandomForestClassifier(featuresCol = FEATURES, labelCol=TARGET)\n",
    "\n",
    "        grid = tune.ParamGridBuilder() \\\n",
    "            .addGrid(random_forest.maxBins, [2, 3]) \\\n",
    "            .addGrid(random_forest.maxDepth, [3, 5]) \\\n",
    "            .addGrid(random_forest.numTrees, [100, 500]) \\\n",
    "            .build()\n",
    "\n",
    "        self.cvModel = tune.CrossValidator( \n",
    "            estimator=random_forest, \n",
    "            estimatorParamMaps=grid, \n",
    "            evaluator=self.evaluator,\n",
    "            numFolds=5\n",
    "        )\n",
    "    \n",
    "    def build_val_model(self, hyper_dict):\n",
    "        from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "        print('Build ValModel: Random Forest')\n",
    "\n",
    "        self.valModel = RandomForestClassifier(\n",
    "            featuresCol = FEATURES, \n",
    "            labelCol=TARGET, \n",
    "            **self.results.cv_best_hyperparameters\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticModel(Model):\n",
    "    \n",
    "    def __init__(self, list_features):\n",
    "        \n",
    "        Model.__init__(\n",
    "            self, \n",
    "            list_features = list_features, \n",
    "            model_type = 'Logistic'\n",
    "        )\n",
    "        \n",
    "    def build_cv_model(self):\n",
    "        from pyspark.ml.classification import LogisticRegression\n",
    "        import pyspark.ml.tuning as tune\n",
    "\n",
    "        print('Build CVModel: Logistic Regression')\n",
    "\n",
    "        logistic = LogisticRegression(featuresCol = FEATURES, labelCol=TARGET)\n",
    "\n",
    "        grid = tune.ParamGridBuilder() \\\n",
    "            .addGrid(logistic.maxIter, [10, 20]) \\\n",
    "            .addGrid(logistic.regParam, [0.1, 0.5]) \\\n",
    "            .build()\n",
    "\n",
    "        self.cvModel = tune.CrossValidator( \n",
    "            estimator=logistic, \n",
    "            estimatorParamMaps=grid, \n",
    "            evaluator=self.evaluator,\n",
    "            numFolds=5\n",
    "        )\n",
    "    \n",
    "    def build_val_model(self):\n",
    "        from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "        print('Build ValModel: Logistic Regression')\n",
    "\n",
    "        self.valModel = LogisticRegression(\n",
    "            featuresCol = FEATURES, \n",
    "            labelCol=TARGET, \n",
    "            **self.results.cv_best_hyperparameters\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/project/ds5559/group2nba/stacked_data/NBA_PBP_2018-19.csv']\n"
     ]
    }
   ],
   "source": [
    "train_files = [\n",
    "#     'NBA_PBP_2015-16.csv',\n",
    "#     'NBA_PBP_2016-17.csv',\n",
    "#     'NBA_PBP_2017-18.csv',\n",
    "    'NBA_PBP_2018-19.csv'\n",
    "]\n",
    "\n",
    "validation_file = 'NBA_PBP_2019-20.csv'\n",
    "\n",
    "# Read in all Train_Files\n",
    "\n",
    "file_list = []\n",
    "for item in train_files:\n",
    "    file_list.append(PATH_STACKED + item)\n",
    "    \n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_file(full_file_name):\n",
    "\n",
    "    df = spark.read \\\n",
    "        .format('csv') \\\n",
    "        .option('header', True) \\\n",
    "        .schema(schema) \\\n",
    "        .load(full_file_name)\n",
    "\n",
    "#     display(df.count())\n",
    "#     display(df.printSchema())\n",
    "#     display(df.head(2))\n",
    "    \n",
    "    return df\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "df = spark.read.csv(file_list)\n",
    "\n",
    "# test_train = 'NBA_PBP_2015-16.csv'\n",
    "validation = 'NBA_PBP_2019-20.csv'\n",
    "\n",
    "# # Load in your data - Can append more files to test_train if you want\n",
    "# #   by extending the 'read_in_files' with ',' between full file names\n",
    "test_train_df = read_in_file(file_list)\n",
    "validation_df = read_in_file(join(PATH_STACKED, validation))\n",
    "\n",
    "# Any Modifications to the Data you want to make\n",
    "# test_train_df = test_train_df.where(F.col('SecLeftTotal') <= 300)\n",
    "# validation_df = validation_df.where(F.col('SecLeftTotal') <= 300)\n",
    "\n",
    "# test_model = SVMModel(list_features, test_train_df, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results):\n",
    "    from os.path import exists\n",
    "\n",
    "    results_df = pd.DataFrame(data=[results])\n",
    "\n",
    "    file_exists = exists(RESULTS_FILE)\n",
    "    if file_exists:\n",
    "        results_df.to_csv(RESULTS_FILE, mode='a', index=False, header=False, sep=\"|\")\n",
    "    else:\n",
    "        results_df.to_csv(RESULTS_FILE, mode='w', index=False, header=True, sep=\"|\")\n",
    "\n",
    "def run_model(test_model):\n",
    "\n",
    "    # Run Cross Validation (Find Best Hyperparameters)\n",
    "    test_model.build_cv_model()\n",
    "    test_model.evaluate_cv_model(test_train_df)\n",
    "\n",
    "    # Run Model Validation\n",
    "    test_model.build_val_model()\n",
    "    test_model.evaluate_val_model(test_train_df, validation_df)\n",
    "\n",
    "    # Save the Results\n",
    "    save_results(test_model.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Model\n",
      "build the pipeline\n",
      "Build CVModel: Logistic Regression\n",
      "Build Data Transformer\n",
      "Transform Train Data + Fit CV Model\n",
      "Transform Test Data\n",
      "Evaluate Model Against Test Data\n",
      "Store Results\n",
      "{'maxIter': 20, 'regParam': 0.1}\n",
      "Build ValModel: Logistic Regression\n",
      "Build Data Transformer\n",
      "Transform TestTrain Data + Fit Val Model\n",
      "Transform Validation Data\n",
      "Evaluate Model Against Validation Data\n",
      "Store Results\n"
     ]
    }
   ],
   "source": [
    "#   'HasPossession', 'assist_team_cnt', 'assist_opponent_cnt', 'turnover_team_cnt'\n",
    "# , 'turnover_opponent_cnt', 'block_team_cnt', 'block_opponent_cnt'\n",
    "# , 'foul_team_cnt', 'foul_opponent_cnt', 'rebound_team_cnt', 'rebound_opponent_cnt'\n",
    "# , 'shotOnGoal_team_cnt', 'shotOnGoal_opponent_cnt', 'freeThrow_team_cnt'\n",
    "# , 'freeThrow_opponent_cnt'\n",
    "# , 'SecLeftTotalInverseTimesScoreDiff'\n",
    "# , 'assist_diff', 'turnover_diff', 'block_diff', 'foul_diff', 'rebound_diff'\n",
    "# , 'shotOnGoal_diff', 'freeThrow_diff'\n",
    "\n",
    "# LogSecLeftTotal\n",
    "list_features = ['ScoreDiff', 'SecLeftTotalInverseTimesScoreDiff', 'shotOnGoal_diff', 'freeThrow_diff']\n",
    "\n",
    "# test_model = SVMModel(list_features)\n",
    "# run_model(test_model)\n",
    "\n",
    "test_model = LogisticModel(list_features)\n",
    "run_model(test_model)\n",
    "\n",
    "# test_model = RandomForestModel(list_features)\n",
    "# run_model(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>list_features</th>\n",
       "      <th>date_time_run</th>\n",
       "      <th>user</th>\n",
       "      <th>special_description</th>\n",
       "      <th>cv_elapsed_time</th>\n",
       "      <th>cv_area_under_roc</th>\n",
       "      <th>cv_area_under_pr</th>\n",
       "      <th>cv_best_coefficients</th>\n",
       "      <th>cv_best_hyperparameters</th>\n",
       "      <th>val_elapsed_time</th>\n",
       "      <th>val_area_under_roc</th>\n",
       "      <th>val_area_under_pr</th>\n",
       "      <th>val_best_coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['ScoreDiff']</td>\n",
       "      <td>04/19/2022 20:23:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>472.38</td>\n",
       "      <td>0.820769</td>\n",
       "      <td>0.823068</td>\n",
       "      <td>[0.87075747]</td>\n",
       "      <td>{'maxIter': 10, 'regParam': 0.1}</td>\n",
       "      <td>59.60</td>\n",
       "      <td>0.817860</td>\n",
       "      <td>0.819785</td>\n",
       "      <td>[0.87109063]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>['ScoreDiff']</td>\n",
       "      <td>04/19/2022 20:27:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>988.27</td>\n",
       "      <td>0.821035</td>\n",
       "      <td>0.821572</td>\n",
       "      <td>[1.62930303]</td>\n",
       "      <td>{'aggregationDepth': 3, 'maxIter': 10}</td>\n",
       "      <td>34.96</td>\n",
       "      <td>0.817860</td>\n",
       "      <td>0.819785</td>\n",
       "      <td>[1.47594578e+09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>['ScoreDiff']</td>\n",
       "      <td>04/19/2022 20:34:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>902.61</td>\n",
       "      <td>0.821035</td>\n",
       "      <td>0.821572</td>\n",
       "      <td>[1.62930303]</td>\n",
       "      <td>{'aggregationDepth': 3, 'maxIter': 10}</td>\n",
       "      <td>36.78</td>\n",
       "      <td>0.817860</td>\n",
       "      <td>0.819785</td>\n",
       "      <td>[2.8556276e+08]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>['ScoreDiff', 'SecLeftTotalInverseTimesScoreDi...</td>\n",
       "      <td>04/19/2022 20:47:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480.61</td>\n",
       "      <td>0.832802</td>\n",
       "      <td>0.838319</td>\n",
       "      <td>[ 1.01078881e+00  2.24112281e+01  1.19773423e-...</td>\n",
       "      <td>{'aggregationDepth': 3, 'maxIter': 50}</td>\n",
       "      <td>52.09</td>\n",
       "      <td>0.827862</td>\n",
       "      <td>0.834613</td>\n",
       "      <td>[ 1.01002416e+00  2.27749401e+01  1.19473884e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['ScoreDiff', 'SecLeftTotalInverseTimesScoreDi...</td>\n",
       "      <td>04/19/2022 20:56:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.57</td>\n",
       "      <td>0.818553</td>\n",
       "      <td>0.820808</td>\n",
       "      <td>[ 0.67589145  0.10302677  0.25983444 -0.154286...</td>\n",
       "      <td>{'maxIter': 10, 'regParam': 0.1}</td>\n",
       "      <td>40.08</td>\n",
       "      <td>0.806692</td>\n",
       "      <td>0.809051</td>\n",
       "      <td>[ 0.67622056  0.10278427  0.26000813 -0.154158...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_type                                      list_features  \\\n",
       "0                Logistic                                      ['ScoreDiff']   \n",
       "1  Support Vector Machine                                      ['ScoreDiff']   \n",
       "2  Support Vector Machine                                      ['ScoreDiff']   \n",
       "3  Support Vector Machine  ['ScoreDiff', 'SecLeftTotalInverseTimesScoreDi...   \n",
       "4                Logistic  ['ScoreDiff', 'SecLeftTotalInverseTimesScoreDi...   \n",
       "\n",
       "         date_time_run  user  special_description  cv_elapsed_time  \\\n",
       "0  04/19/2022 20:23:11   NaN                  NaN           472.38   \n",
       "1  04/19/2022 20:27:43   NaN                  NaN           988.27   \n",
       "2  04/19/2022 20:34:56   NaN                  NaN           902.61   \n",
       "3  04/19/2022 20:47:19   NaN                  NaN           480.61   \n",
       "4  04/19/2022 20:56:12   NaN                  NaN           166.57   \n",
       "\n",
       "   cv_area_under_roc  cv_area_under_pr  \\\n",
       "0           0.820769          0.823068   \n",
       "1           0.821035          0.821572   \n",
       "2           0.821035          0.821572   \n",
       "3           0.832802          0.838319   \n",
       "4           0.818553          0.820808   \n",
       "\n",
       "                                cv_best_coefficients  \\\n",
       "0                                       [0.87075747]   \n",
       "1                                       [1.62930303]   \n",
       "2                                       [1.62930303]   \n",
       "3  [ 1.01078881e+00  2.24112281e+01  1.19773423e-...   \n",
       "4  [ 0.67589145  0.10302677  0.25983444 -0.154286...   \n",
       "\n",
       "                  cv_best_hyperparameters  val_elapsed_time  \\\n",
       "0        {'maxIter': 10, 'regParam': 0.1}             59.60   \n",
       "1  {'aggregationDepth': 3, 'maxIter': 10}             34.96   \n",
       "2  {'aggregationDepth': 3, 'maxIter': 10}             36.78   \n",
       "3  {'aggregationDepth': 3, 'maxIter': 50}             52.09   \n",
       "4        {'maxIter': 10, 'regParam': 0.1}             40.08   \n",
       "\n",
       "   val_area_under_roc  val_area_under_pr  \\\n",
       "0            0.817860           0.819785   \n",
       "1            0.817860           0.819785   \n",
       "2            0.817860           0.819785   \n",
       "3            0.827862           0.834613   \n",
       "4            0.806692           0.809051   \n",
       "\n",
       "                               val_best_coefficients  \n",
       "0                                       [0.87109063]  \n",
       "1                                   [1.47594578e+09]  \n",
       "2                                    [2.8556276e+08]  \n",
       "3  [ 1.01002416e+00  2.27749401e+01  1.19473884e-...  \n",
       "4  [ 0.67622056  0.10278427  0.26000813 -0.154158...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_df = pd.read_csv(RESULTS_FILE, sep='|')\n",
    "view_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=3, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=3, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=4, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=5, prediction=1.0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "test_model.val_predictions.where((F.col('Won') != 1) & (F.col('ScoreDiff') > 1)).select('Won', 'ScoreDiff', 'prediction').take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(test_model.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388320\n",
      "150746\n",
      "149527\n",
      "389539\n"
     ]
    }
   ],
   "source": [
    "print(test_model.val_predictions.where((F.col('Won') == 1) & (F.col('prediction') == 1)).count())\n",
    "print(test_model.val_predictions.where((F.col('Won') == 1) & (F.col('prediction') == 0)).count())\n",
    "print(test_model.val_predictions.where((F.col('Won') == 0) & (F.col('prediction') == 1)).count())\n",
    "print(test_model.val_predictions.where((F.col('Won') == 0) & (F.col('prediction') == 0)).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
