{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "\n",
    "PATH_MAIN = '/project/ds5559/group2nba'\n",
    "PATH_STACKED = f'{PATH_MAIN}/stacked_data/'\n",
    "RESULTS_FILE = f'{PATH_MAIN}/results_expanded.csv'\n",
    "TARGET = 'Won'\n",
    "FEATURES = 'features'\n",
    "\n",
    "CORES = 4\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('group2nba') \\\n",
    "    .master(f'local[{CORES}]') \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from typing import *\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "FIELDS: Dict[str, T] = {\n",
    "      'Date': StringType\n",
    "    , 'HomeTeam': StringType\n",
    "    , 'AwayTeam': StringType\n",
    "    , 'Team': StringType\n",
    "    , 'Year': IntegerType\n",
    "    , 'Won': IntegerType\n",
    "    \n",
    "    , 'ScoreDiff': IntegerType\n",
    "    , 'Quarter': IntegerType\n",
    "    , 'SecLeftTotal': IntegerType\n",
    "    , 'LogSecLeftTotal': DoubleType\n",
    "    , 'SecLeftTotalInverse': DoubleType\n",
    "    \n",
    "    , 'HasPossession': IntegerType\n",
    "    , 'assist_team_cnt': LongType\n",
    "    , 'assist_opponent_cnt': LongType\n",
    "    , 'turnover_team_cnt': LongType\n",
    "    , 'turnover_opponent_cnt': LongType\n",
    "    , 'block_team_cnt': LongType\n",
    "    , 'block_opponent_cnt': LongType\n",
    "    \n",
    "    , 'foul_team_cnt': LongType\n",
    "    , 'foul_opponent_cnt': LongType\n",
    "    , 'rebound_team_cnt': LongType\n",
    "    , 'rebound_opponent_cnt': LongType\n",
    "    , 'shotOnGoal_team_cnt': LongType\n",
    "    , 'shotOnGoal_opponent_cnt': LongType\n",
    "    , 'freeThrow_team_cnt': LongType\n",
    "    , 'freeThrow_opponent_cnt': LongType\n",
    "    \n",
    "    , 'SecLeftTotalInverseTimesScoreDiff': DoubleType\n",
    "    , 'assist_diff': IntegerType\n",
    "    , 'turnover_diff': IntegerType\n",
    "    , 'block_diff': IntegerType\n",
    "    , 'foul_diff': IntegerType\n",
    "    , 'rebound_diff': IntegerType\n",
    "    , 'shotOnGoal_diff': IntegerType\n",
    "    , 'freeThrow_diff': IntegerType\n",
    "}\n",
    "    \n",
    "schema = StructType([StructField(k, v()) for k, v in FIELDS.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class results_cls:\n",
    "    model_type: str = ''\n",
    "    list_features: list = field(default_factory=list)\n",
    "    date_time_run: str = ''\n",
    "    user: str = ''\n",
    "    special_description: str = ''\n",
    "    cv_elapsed_time: str = ''\n",
    "    cv_area_under_roc: float = 0.0\n",
    "    cv_area_under_pr: float = 0.0\n",
    "    cv_best_coefficients: list = field(default_factory=list)\n",
    "    cv_best_hyperparameters: dict = field(default_factory=dict)\n",
    "    val_elapsed_time: str = ''\n",
    "    val_area_under_roc: float = 0.0\n",
    "    val_area_under_pr: float = 0.0\n",
    "    val_best_coefficients: list = field(default_factory=list)\n",
    "\n",
    "# results = results_cls(date_time_run = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "# results.model_type='SVM'\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    logistic = 'Logistic'\n",
    "    random_forest = 'Random Forest'\n",
    "    svm = 'Support Vector Machine'\n",
    "    \n",
    "    TARGET = 'Won'\n",
    "    FEATURES = 'features'\n",
    "    \n",
    "    def __init__(self, list_features, model_type):\n",
    "        from datetime import datetime\n",
    "        \n",
    "        # Defined in Methods\n",
    "        self.cvModel = None\n",
    "        self.cvPredictions = None\n",
    "        self.valModel = None\n",
    "        self.valPredictions = None\n",
    "        \n",
    "        print('Setup Model')\n",
    "        self.list_features = list_features\n",
    "        self.pipeline = self.build_pipeline()\n",
    "        self.model_type = model_type\n",
    "        self.evaluator = self.build_evaluator()\n",
    "        self.results = results_cls(\n",
    "            model_type = model_type,\n",
    "            list_features = list_features,\n",
    "            date_time_run = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "        )\n",
    "        \n",
    "    def build_pipeline(self):\n",
    "        from pyspark.ml import feature as ft\n",
    "        from pyspark.ml import Pipeline\n",
    "\n",
    "        # Build the Pipeline\n",
    "        print('build the pipeline')\n",
    "\n",
    "        featuresCreator = ft.VectorAssembler(\n",
    "            inputCols=self.list_features,\n",
    "            outputCol='vectors'\n",
    "        )\n",
    "\n",
    "        sScaler = ft.StandardScaler(\n",
    "            withMean=True, \n",
    "            withStd=True, \n",
    "            inputCol='vectors', \n",
    "            outputCol='features'\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline(\n",
    "            stages=[\n",
    "                featuresCreator,\n",
    "                sScaler\n",
    "            ])\n",
    "\n",
    "        return pipeline\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_evaluator():\n",
    "        import pyspark.ml.evaluation as ev\n",
    "\n",
    "        evaluator = ev.BinaryClassificationEvaluator(\n",
    "            metricName = 'areaUnderROC',\n",
    "            rawPredictionCol='rawPrediction', \n",
    "            labelCol=TARGET\n",
    "        )\n",
    "        \n",
    "        return evaluator\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_hyperparams(cvModel):\n",
    "        import re\n",
    "\n",
    "        hyperparams = cvModel.getEstimatorParamMaps()[ np.argmax(cvModel.avgMetrics) ]\n",
    "        hyper_dict = {}\n",
    "\n",
    "        for i in range(len(hyperparams.items())):\n",
    "            hyper_name = re.search(\"name='(.+?)'\", str([x for x in hyperparams.items()][i])).group(1)\n",
    "            hyper_value = [x for x in hyperparams.items()][i][1]\n",
    "\n",
    "            hyper_dict[hyper_name]= hyper_value\n",
    "\n",
    "        print(hyper_dict)\n",
    "    \n",
    "        return hyper_dict\n",
    "    \n",
    "    def evaluate_cv_model(self, test_train_data):\n",
    "        import time\n",
    "\n",
    "        # Start the Timer\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_data, test_data = test_train_data.randomSplit([0.7, 0.3], seed=123) \n",
    "\n",
    "        # Fit the Model\n",
    "        print('Build Data Transformer')\n",
    "        data_transformer = self.pipeline.fit(train_data)\n",
    "\n",
    "        print('Transform Train Data + Fit CV Model')\n",
    "        cvModel = self.cvModel.setParallelism(CORES).fit(data_transformer.transform(train_data))\n",
    "\n",
    "        print('Transform Test Data')\n",
    "        data_train = data_transformer.transform(test_data)\n",
    "\n",
    "        print('Evaluate Model Against Test Data')\n",
    "        self.cv_predictions = cvModel.transform(data_train)\n",
    "\n",
    "        print('Store Results')\n",
    "        \n",
    "        self.results.cv_area_under_roc = self.evaluator.evaluate(\n",
    "            self.cv_predictions, \n",
    "            {self.evaluator.metricName: 'areaUnderROC'}\n",
    "        )\n",
    "        self.results.cv_area_under_pr = self.evaluator.evaluate(\n",
    "            self.cv_predictions, \n",
    "            {self.evaluator.metricName: 'areaUnderPR'}\n",
    "        )\n",
    "\n",
    "        # End Timer\n",
    "        self.results.cv_elapsed_time = round((time.time() - start_time), 2)\n",
    "\n",
    "        # Random Forest doesn't have coefficients\n",
    "        if self.model_type in (self.logistic, self.svm):\n",
    "            self.results.cv_best_coefficients = cvModel.bestModel.coefficients\n",
    "            \n",
    "        self.results.cv_best_hyperparameters = self.extract_hyperparams(cvModel)\n",
    "        \n",
    "    def evaluate_val_model(self, test_train_data, validation_data):\n",
    "        import time\n",
    "\n",
    "        # Start the Timer\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print('Build Data Transformer')\n",
    "        data_transformer = self.pipeline.fit(test_train_data)\n",
    "\n",
    "        print('Transform TestTrain Data + Fit Val Model')\n",
    "        valModel = self.valModel.fit(data_transformer.transform(test_train_data))\n",
    "        \n",
    "        print('Transform Validation Data')\n",
    "        data_train = data_transformer.transform(validation_data)\n",
    "\n",
    "        print('Evaluate Model Against Validation Data')\n",
    "        self.val_predictions = valModel.transform(data_train)\n",
    "        \n",
    "        print('Store Results')\n",
    "        \n",
    "        self.results.val_area_under_roc = self.evaluator.evaluate(\n",
    "            self.val_predictions, \n",
    "            {self.evaluator.metricName: 'areaUnderROC'}\n",
    "        )\n",
    "        self.results.val_area_under_pr = self.evaluator.evaluate(\n",
    "            self.val_predictions, \n",
    "            {self.evaluator.metricName: 'areaUnderPR'}\n",
    "        )\n",
    "\n",
    "        # End Timer\n",
    "        self.results.val_elapsed_time = round((time.time() - start_time), 2)\n",
    "\n",
    "        # Random Forest doesn't have coefficients\n",
    "        if self.model_type in (self.logistic, self.svm):\n",
    "            self.results.val_best_coefficients = valModel.coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMModel(Model):\n",
    "\n",
    "    def __init__(self, list_features):\n",
    "        Model.__init__(\n",
    "            self, \n",
    "            list_features = list_features, \n",
    "            model_type = 'Support Vector Machine'\n",
    "        )\n",
    "        \n",
    "    def build_cv_model(self):\n",
    "        import pyspark.ml.evaluation as ev\n",
    "        from pyspark.ml.classification import LinearSVC\n",
    "        import pyspark.ml.tuning as tune\n",
    "\n",
    "        print('Build CVModel: SVM')\n",
    "\n",
    "        svm = LinearSVC(featuresCol = FEATURES, labelCol=TARGET)\n",
    "\n",
    "        grid = tune.ParamGridBuilder() \\\n",
    "                    .addGrid(svm.aggregationDepth, [3, 5, 10]) \\\n",
    "                    .addGrid(svm.maxIter, [10, 20, 50]) \\\n",
    "                    .build()\n",
    "\n",
    "        self.cvModel = tune.CrossValidator( \n",
    "            estimator=svm, \n",
    "            estimatorParamMaps=grid, \n",
    "            evaluator=self.evaluator,\n",
    "            numFolds=5\n",
    "        )\n",
    "    \n",
    "    def build_val_model(self):\n",
    "        from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "        print('Build ValModel: SVM')\n",
    "\n",
    "        self.valModel = LinearSVC(\n",
    "            featuresCol = FEATURES, \n",
    "            labelCol=TARGET, \n",
    "            **self.results.cv_best_hyperparameters\n",
    "        )\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestModel(Model):\n",
    "\n",
    "    def __init__(self, list_features):\n",
    "        Model.__init__(\n",
    "            self, \n",
    "            list_features = list_features, \n",
    "            model_type = 'Random Forest'\n",
    "        )\n",
    "        \n",
    "    def build_cv_model(self):\n",
    "        from pyspark.ml.classification import RandomForestClassifier\n",
    "        import pyspark.ml.tuning as tune\n",
    "\n",
    "        print('Build CVModel: Random Forest')\n",
    "\n",
    "        random_forest = RandomForestClassifier(featuresCol = FEATURES, labelCol=TARGET)\n",
    "\n",
    "        grid = tune.ParamGridBuilder() \\\n",
    "            .addGrid(random_forest.maxBins, [2, 3]) \\\n",
    "            .addGrid(random_forest.maxDepth, [3, 5]) \\\n",
    "            .addGrid(random_forest.numTrees, [100, 500]) \\\n",
    "            .build()\n",
    "\n",
    "        self.cvModel = tune.CrossValidator( \n",
    "            estimator=random_forest, \n",
    "            estimatorParamMaps=grid, \n",
    "            evaluator=self.evaluator,\n",
    "            numFolds=5\n",
    "        )\n",
    "    \n",
    "    def build_val_model(self, hyper_dict):\n",
    "        from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "        print('Build ValModel: Random Forest')\n",
    "\n",
    "        self.valModel = RandomForestClassifier(\n",
    "            featuresCol = FEATURES, \n",
    "            labelCol=TARGET, \n",
    "            **self.results.cv_best_hyperparameters\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticModel(Model):\n",
    "    \n",
    "    def __init__(self, list_features):\n",
    "        \n",
    "        Model.__init__(\n",
    "            self, \n",
    "            list_features = list_features, \n",
    "            model_type = 'Logistic'\n",
    "        )\n",
    "        \n",
    "    def build_cv_model(self):\n",
    "        from pyspark.ml.classification import LogisticRegression\n",
    "        import pyspark.ml.tuning as tune\n",
    "\n",
    "        print('Build CVModel: Logistic Regression')\n",
    "\n",
    "        logistic = LogisticRegression(featuresCol = FEATURES, labelCol=TARGET)\n",
    "\n",
    "        grid = tune.ParamGridBuilder() \\\n",
    "            .addGrid(logistic.maxIter, [10, 20]) \\\n",
    "            .addGrid(logistic.regParam, [0.1, 0.5]) \\\n",
    "            .build()\n",
    "\n",
    "        self.cvModel = tune.CrossValidator( \n",
    "            estimator=logistic, \n",
    "            estimatorParamMaps=grid, \n",
    "            evaluator=self.evaluator,\n",
    "            numFolds=5\n",
    "        )\n",
    "    \n",
    "    def build_val_model(self):\n",
    "        from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "        print('Build ValModel: Logistic Regression')\n",
    "\n",
    "        self.valModel = LogisticRegression(\n",
    "            featuresCol = FEATURES, \n",
    "            labelCol=TARGET, \n",
    "            **self.results.cv_best_hyperparameters\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/project/ds5559/group2nba/stacked_data/NBA_PBP_2015-16.csv', '/project/ds5559/group2nba/stacked_data/NBA_PBP_2016-17.csv', '/project/ds5559/group2nba/stacked_data/NBA_PBP_2017-18.csv', '/project/ds5559/group2nba/stacked_data/NBA_PBP_2018-19.csv']\n"
     ]
    }
   ],
   "source": [
    "train_files = [\n",
    "    'NBA_PBP_2015-16.csv',\n",
    "    'NBA_PBP_2016-17.csv',\n",
    "    'NBA_PBP_2017-18.csv',\n",
    "    'NBA_PBP_2018-19.csv'\n",
    "]\n",
    "\n",
    "validation_file = 'NBA_PBP_2019-20.csv'\n",
    "\n",
    "# Read in all Train_Files\n",
    "\n",
    "file_list = []\n",
    "for item in train_files:\n",
    "    file_list.append(PATH_STACKED + item)\n",
    "    \n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_file(full_file_name):\n",
    "\n",
    "    df = spark.read \\\n",
    "        .format('csv') \\\n",
    "        .option('header', True) \\\n",
    "        .schema(schema) \\\n",
    "        .load(full_file_name)\n",
    "\n",
    "#     display(df.count())\n",
    "#     display(df.printSchema())\n",
    "#     display(df.head(2))\n",
    "    \n",
    "    return df\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "df = spark.read.csv(file_list)\n",
    "\n",
    "# test_train = 'NBA_PBP_2015-16.csv'\n",
    "validation = 'NBA_PBP_2019-20.csv'\n",
    "\n",
    "# # Load in your data - Can append more files to test_train if you want\n",
    "# #   by extending the 'read_in_files' with ',' between full file names\n",
    "test_train_df = read_in_file(file_list)\n",
    "validation_df = read_in_file(join(PATH_STACKED, validation))\n",
    "\n",
    "# Any Modifications to the Data you want to make\n",
    "# test_train_df = test_train_df.where(F.col('SecLeftTotal') <= 300)\n",
    "# validation_df = validation_df.where(F.col('SecLeftTotal') <= 300)\n",
    "\n",
    "# test_model = SVMModel(list_features, test_train_df, validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results):\n",
    "    from os.path import exists\n",
    "\n",
    "    results_df = pd.DataFrame(data=[results])\n",
    "\n",
    "    file_exists = exists(RESULTS_FILE)\n",
    "    if file_exists:\n",
    "        results_df.to_csv(RESULTS_FILE, mode='a', index=False, header=False, sep=\"|\")\n",
    "    else:\n",
    "        results_df.to_csv(RESULTS_FILE, mode='w', index=False, header=True, sep=\"|\")\n",
    "\n",
    "def run_model(test_model):\n",
    "\n",
    "    # Run Cross Validation (Find Best Hyperparameters)\n",
    "    test_model.build_cv_model()\n",
    "    test_model.evaluate_cv_model(test_train_df)\n",
    "\n",
    "    # Run Model Validation\n",
    "    test_model.build_val_model()\n",
    "    test_model.evaluate_val_model(test_train_df, validation_df)\n",
    "\n",
    "    # Save the Results\n",
    "    save_results(test_model.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Model\n",
      "build the pipeline\n",
      "Build CVModel: Logistic Regression\n",
      "Build Data Transformer\n",
      "Transform Train Data + Fit CV Model\n"
     ]
    }
   ],
   "source": [
    "#   'HasPossession', 'assist_team_cnt', 'assist_opponent_cnt', 'turnover_team_cnt'\n",
    "# , 'turnover_opponent_cnt', 'block_team_cnt', 'block_opponent_cnt'\n",
    "# , 'foul_team_cnt', 'foul_opponent_cnt', 'rebound_team_cnt', 'rebound_opponent_cnt'\n",
    "# , 'shotOnGoal_team_cnt', 'shotOnGoal_opponent_cnt', 'freeThrow_team_cnt'\n",
    "# , 'freeThrow_opponent_cnt'\n",
    "# , 'SecLeftTotalInverseTimesScoreDiff'\n",
    "# , 'assist_diff', 'turnover_diff', 'block_diff', 'foul_diff', 'rebound_diff'\n",
    "# , 'shotOnGoal_diff', 'freeThrow_diff'\n",
    "\n",
    "# LogSecLeftTotal\n",
    "list_features = ['ScoreDiff']\n",
    "\n",
    "# test_model = SVMModel(list_features)\n",
    "# run_model(test_model)\n",
    "\n",
    "test_model = LogisticModel(list_features)\n",
    "run_model(test_model)\n",
    "\n",
    "# test_model = RandomForestModel(list_features)\n",
    "# run_model(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>list_features</th>\n",
       "      <th>date_time_run</th>\n",
       "      <th>user</th>\n",
       "      <th>special_description</th>\n",
       "      <th>cv_elapsed_time</th>\n",
       "      <th>cv_area_under_roc</th>\n",
       "      <th>cv_area_under_pr</th>\n",
       "      <th>cv_best_coefficients</th>\n",
       "      <th>cv_best_hyperparameters</th>\n",
       "      <th>val_elapsed_time</th>\n",
       "      <th>val_area_under_roc</th>\n",
       "      <th>val_area_under_pr</th>\n",
       "      <th>val_best_coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>04/19/2022 19:09:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.20</td>\n",
       "      <td>0.980536</td>\n",
       "      <td>0.981152</td>\n",
       "      <td>[ 0.50661366 -0.00099486  0.11844983]</td>\n",
       "      <td>{}</td>\n",
       "      <td>12.56</td>\n",
       "      <td>0.981701</td>\n",
       "      <td>0.982327</td>\n",
       "      <td>[5.06565419e-01 8.31596062e-18 1.18880671e-01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>04/19/2022 19:25:37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.73</td>\n",
       "      <td>0.980539</td>\n",
       "      <td>0.981151</td>\n",
       "      <td>[ 0.50661366 -0.00099486  0.11844983]</td>\n",
       "      <td>{}</td>\n",
       "      <td>12.10</td>\n",
       "      <td>0.981703</td>\n",
       "      <td>0.982326</td>\n",
       "      <td>[5.06565419e-01 5.08373086e-18 1.18880671e-01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>04/19/2022 19:25:37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.73</td>\n",
       "      <td>0.980539</td>\n",
       "      <td>0.981151</td>\n",
       "      <td>[ 0.50661366 -0.00099486  0.11844983]</td>\n",
       "      <td>{}</td>\n",
       "      <td>12.10</td>\n",
       "      <td>0.981703</td>\n",
       "      <td>0.982326</td>\n",
       "      <td>[5.06565419e-01 5.08373086e-18 1.18880671e-01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>[]</td>\n",
       "      <td>04/19/2022 19:30:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.32</td>\n",
       "      <td>0.980542</td>\n",
       "      <td>0.981152</td>\n",
       "      <td>[ 0.50661366 -0.00099486  0.11844983]</td>\n",
       "      <td>{}</td>\n",
       "      <td>11.63</td>\n",
       "      <td>0.981703</td>\n",
       "      <td>0.982326</td>\n",
       "      <td>[5.06565419e-01 5.69033792e-18 1.18880671e-01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['ScoreDiff', 'SecLeftTotalInverse', 'SecLeftT...</td>\n",
       "      <td>04/19/2022 19:37:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.47</td>\n",
       "      <td>0.980539</td>\n",
       "      <td>0.981150</td>\n",
       "      <td>[ 0.50661366 -0.00099486  0.11844983]</td>\n",
       "      <td>{}</td>\n",
       "      <td>11.17</td>\n",
       "      <td>0.981694</td>\n",
       "      <td>0.982325</td>\n",
       "      <td>[5.06565419e-01 5.08798883e-18 1.18880671e-01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['ScoreDiff', 'SecLeftTotalInverse', 'SecLeftT...</td>\n",
       "      <td>04/19/2022 19:42:58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.17</td>\n",
       "      <td>0.980542</td>\n",
       "      <td>0.981152</td>\n",
       "      <td>[ 0.50661366 -0.00099486  0.11844983]</td>\n",
       "      <td>{'maxIter': 20, 'regParam': 0.5}</td>\n",
       "      <td>12.04</td>\n",
       "      <td>0.981702</td>\n",
       "      <td>0.982329</td>\n",
       "      <td>[5.06565419e-01 1.01821348e-17 1.18880671e-01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['ScoreDiff', 'SecLeftTotalInverse', 'SecLeftT...</td>\n",
       "      <td>04/19/2022 19:46:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.99</td>\n",
       "      <td>0.984891</td>\n",
       "      <td>0.985332</td>\n",
       "      <td>[0.50903018 0.00076816 0.12166393]</td>\n",
       "      <td>{'maxIter': 20, 'regParam': 0.5}</td>\n",
       "      <td>11.86</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.982328</td>\n",
       "      <td>[5.08990856e-01 3.46960544e-18 1.21583108e-01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['ScoreDiff', 'SecLeftTotalInverse']</td>\n",
       "      <td>04/19/2022 19:50:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.16</td>\n",
       "      <td>0.983363</td>\n",
       "      <td>0.984160</td>\n",
       "      <td>[0.51731155 0.00091616]</td>\n",
       "      <td>{'maxIter': 10, 'regParam': 0.5}</td>\n",
       "      <td>11.22</td>\n",
       "      <td>0.979936</td>\n",
       "      <td>0.980646</td>\n",
       "      <td>[5.17276795e-01 1.48025348e-18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['ScoreDiff']</td>\n",
       "      <td>04/19/2022 19:52:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.71</td>\n",
       "      <td>0.983404</td>\n",
       "      <td>0.983935</td>\n",
       "      <td>[1.34998164]</td>\n",
       "      <td>{'maxIter': 10, 'regParam': 0.1}</td>\n",
       "      <td>11.75</td>\n",
       "      <td>0.979936</td>\n",
       "      <td>0.980652</td>\n",
       "      <td>[1.35004335]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['ScoreDiff']</td>\n",
       "      <td>04/19/2022 20:12:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.03</td>\n",
       "      <td>0.834392</td>\n",
       "      <td>0.837142</td>\n",
       "      <td>[0.90569828]</td>\n",
       "      <td>{'maxIter': 10, 'regParam': 0.1}</td>\n",
       "      <td>24.17</td>\n",
       "      <td>0.817860</td>\n",
       "      <td>0.819785</td>\n",
       "      <td>[0.90682137]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type                                      list_features  \\\n",
       "0        NaN                                                 []   \n",
       "1        NaN                                                 []   \n",
       "2        NaN                                                 []   \n",
       "3   Logistic                                                 []   \n",
       "4   Logistic  ['ScoreDiff', 'SecLeftTotalInverse', 'SecLeftT...   \n",
       "5   Logistic  ['ScoreDiff', 'SecLeftTotalInverse', 'SecLeftT...   \n",
       "6   Logistic  ['ScoreDiff', 'SecLeftTotalInverse', 'SecLeftT...   \n",
       "7   Logistic               ['ScoreDiff', 'SecLeftTotalInverse']   \n",
       "8   Logistic                                      ['ScoreDiff']   \n",
       "9   Logistic                                      ['ScoreDiff']   \n",
       "\n",
       "         date_time_run  user  special_description  cv_elapsed_time  \\\n",
       "0  04/19/2022 19:09:36   NaN                  NaN            59.20   \n",
       "1  04/19/2022 19:25:37   NaN                  NaN            52.73   \n",
       "2  04/19/2022 19:25:37   NaN                  NaN            52.73   \n",
       "3  04/19/2022 19:30:01   NaN                  NaN            57.32   \n",
       "4  04/19/2022 19:37:12   NaN                  NaN            51.47   \n",
       "5  04/19/2022 19:42:58   NaN                  NaN            55.17   \n",
       "6  04/19/2022 19:46:19   NaN                  NaN            51.99   \n",
       "7  04/19/2022 19:50:03   NaN                  NaN            56.16   \n",
       "8  04/19/2022 19:52:49   NaN                  NaN            50.71   \n",
       "9  04/19/2022 20:12:32   NaN                  NaN           125.03   \n",
       "\n",
       "   cv_area_under_roc  cv_area_under_pr                   cv_best_coefficients  \\\n",
       "0           0.980536          0.981152  [ 0.50661366 -0.00099486  0.11844983]   \n",
       "1           0.980539          0.981151  [ 0.50661366 -0.00099486  0.11844983]   \n",
       "2           0.980539          0.981151  [ 0.50661366 -0.00099486  0.11844983]   \n",
       "3           0.980542          0.981152  [ 0.50661366 -0.00099486  0.11844983]   \n",
       "4           0.980539          0.981150  [ 0.50661366 -0.00099486  0.11844983]   \n",
       "5           0.980542          0.981152  [ 0.50661366 -0.00099486  0.11844983]   \n",
       "6           0.984891          0.985332     [0.50903018 0.00076816 0.12166393]   \n",
       "7           0.983363          0.984160                [0.51731155 0.00091616]   \n",
       "8           0.983404          0.983935                           [1.34998164]   \n",
       "9           0.834392          0.837142                           [0.90569828]   \n",
       "\n",
       "            cv_best_hyperparameters  val_elapsed_time  val_area_under_roc  \\\n",
       "0                                {}             12.56            0.981701   \n",
       "1                                {}             12.10            0.981703   \n",
       "2                                {}             12.10            0.981703   \n",
       "3                                {}             11.63            0.981703   \n",
       "4                                {}             11.17            0.981694   \n",
       "5  {'maxIter': 20, 'regParam': 0.5}             12.04            0.981702   \n",
       "6  {'maxIter': 20, 'regParam': 0.5}             11.86            0.981698   \n",
       "7  {'maxIter': 10, 'regParam': 0.5}             11.22            0.979936   \n",
       "8  {'maxIter': 10, 'regParam': 0.1}             11.75            0.979936   \n",
       "9  {'maxIter': 10, 'regParam': 0.1}             24.17            0.817860   \n",
       "\n",
       "   val_area_under_pr                           val_best_coefficients  \n",
       "0           0.982327  [5.06565419e-01 8.31596062e-18 1.18880671e-01]  \n",
       "1           0.982326  [5.06565419e-01 5.08373086e-18 1.18880671e-01]  \n",
       "2           0.982326  [5.06565419e-01 5.08373086e-18 1.18880671e-01]  \n",
       "3           0.982326  [5.06565419e-01 5.69033792e-18 1.18880671e-01]  \n",
       "4           0.982325  [5.06565419e-01 5.08798883e-18 1.18880671e-01]  \n",
       "5           0.982329  [5.06565419e-01 1.01821348e-17 1.18880671e-01]  \n",
       "6           0.982328  [5.08990856e-01 3.46960544e-18 1.21583108e-01]  \n",
       "7           0.980646                 [5.17276795e-01 1.48025348e-18]  \n",
       "8           0.980652                                    [1.35004335]  \n",
       "9           0.819785                                    [0.90682137]  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_df = pd.read_csv(RESULTS_FILE, sep='|')\n",
    "view_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=3, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=3, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=4, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=5, prediction=1.0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "test_model.val_predictions.where((F.col('Won') != 1) & (F.col('ScoreDiff') > 1)).select('Won', 'ScoreDiff', 'prediction').take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(test_model.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
