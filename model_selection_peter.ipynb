{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "\n",
    "PATH_MAIN = '/project/ds5559/group2nba'\n",
    "PATH_STACKED = f'{PATH_MAIN}/stacked_data/'\n",
    "RESULTS_FILE = f'{PATH_MAIN}/results_expanded_bonus.csv'\n",
    "TARGET = 'Won'\n",
    "FEATURES = 'features'\n",
    "\n",
    "CORES = 4\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('group2nba') \\\n",
    "    .master(f'local[{CORES}]') \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from typing import *\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "FIELDS: Dict[str, T] = {\n",
    "      'Date': StringType\n",
    "    , 'HomeTeam': StringType\n",
    "    , 'AwayTeam': StringType\n",
    "    , 'Team': StringType\n",
    "    , 'Year': IntegerType\n",
    "    , 'Won': IntegerType\n",
    "    \n",
    "    , 'ScoreDiff': IntegerType\n",
    "    , 'Quarter': IntegerType\n",
    "    , 'SecLeftTotal': IntegerType\n",
    "    , 'LogSecLeftTotal': DoubleType\n",
    "    , 'SecLeftTotalInverse': DoubleType\n",
    "    \n",
    "    , 'HasPossession': IntegerType\n",
    "    , 'assist_team_cnt': LongType\n",
    "    , 'assist_opponent_cnt': LongType\n",
    "    , 'turnover_team_cnt': LongType\n",
    "    , 'turnover_opponent_cnt': LongType\n",
    "    , 'block_team_cnt': LongType\n",
    "    , 'block_opponent_cnt': LongType\n",
    "    \n",
    "    , 'foul_team_cnt': LongType\n",
    "    , 'foul_opponent_cnt': LongType\n",
    "    , 'rebound_team_cnt': LongType\n",
    "    , 'rebound_opponent_cnt': LongType\n",
    "    , 'shotOnGoal_team_cnt': LongType\n",
    "    , 'shotOnGoal_opponent_cnt': LongType\n",
    "    , 'freeThrow_team_cnt': LongType\n",
    "    , 'freeThrow_opponent_cnt': LongType\n",
    "    \n",
    "    , 'SecLeftTotalInverseTimesScoreDiff': DoubleType\n",
    "    , 'assist_diff': IntegerType\n",
    "    , 'turnover_diff': IntegerType\n",
    "    , 'block_diff': IntegerType\n",
    "    , 'foul_diff': IntegerType\n",
    "    , 'rebound_diff': IntegerType\n",
    "    , 'shotOnGoal_diff': IntegerType\n",
    "    , 'freeThrow_diff': IntegerType\n",
    "}\n",
    "    \n",
    "schema = StructType([StructField(k, v()) for k, v in FIELDS.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class results_cls:\n",
    "    model_type: str = ''\n",
    "    list_features: list = field(default_factory=list)\n",
    "    date_time_run: str = ''\n",
    "    user: str = ''\n",
    "    special_description: str = ''\n",
    "    cv_elapsed_time: str = ''\n",
    "    cv_area_under_roc: float = 0.0\n",
    "    cv_area_under_pr: float = 0.0\n",
    "    cv_best_coefficients: list = field(default_factory=list)\n",
    "    cv_best_hyperparameters: dict = field(default_factory=dict)\n",
    "    val_elapsed_time: str = ''\n",
    "    val_area_under_roc: float = 0.0\n",
    "    val_area_under_pr: float = 0.0\n",
    "    val_best_coefficients: list = field(default_factory=list)\n",
    "    val_true_positive: int = 0\n",
    "    val_true_negative: int = 0\n",
    "    val_false_positive: int = 0\n",
    "    val_false_negative: int = 0\n",
    "\n",
    "# results = results_cls(date_time_run = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\"))\n",
    "# results.model_type='SVM'\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    logistic = 'Logistic'\n",
    "    random_forest = 'Random Forest'\n",
    "    svm = 'Support Vector Machine'\n",
    "    \n",
    "    TARGET = 'Won'\n",
    "    FEATURES = 'features'\n",
    "    \n",
    "    def __init__(self, list_features, model_type):\n",
    "        from datetime import datetime\n",
    "        \n",
    "        # Defined in Methods\n",
    "        self.cvModel = None\n",
    "        self.cvPredictions = None\n",
    "        self.valModel = None\n",
    "        self.valPredictions = None\n",
    "        \n",
    "        print('Setup Model')\n",
    "        self.list_features = list_features\n",
    "        self.pipeline = self.build_pipeline()\n",
    "        self.model_type = model_type\n",
    "        self.evaluator = self.build_evaluator()\n",
    "        self.results = results_cls(\n",
    "            model_type = model_type,\n",
    "            list_features = list_features,\n",
    "            date_time_run = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "        )\n",
    "        \n",
    "    def build_pipeline(self):\n",
    "        from pyspark.ml import feature as ft\n",
    "        from pyspark.ml import Pipeline\n",
    "\n",
    "        # Build the Pipeline\n",
    "        print('build the pipeline')\n",
    "\n",
    "        featuresCreator = ft.VectorAssembler(\n",
    "            inputCols=self.list_features,\n",
    "            outputCol='vectors'\n",
    "        )\n",
    "\n",
    "        sScaler = ft.StandardScaler(\n",
    "            withMean=True, \n",
    "            withStd=True, \n",
    "            inputCol='vectors', \n",
    "            outputCol='features'\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline(\n",
    "            stages=[\n",
    "                featuresCreator,\n",
    "                sScaler\n",
    "            ])\n",
    "\n",
    "        return pipeline\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_evaluator():\n",
    "        import pyspark.ml.evaluation as ev\n",
    "\n",
    "        evaluator = ev.BinaryClassificationEvaluator(\n",
    "            metricName = 'areaUnderROC',\n",
    "            rawPredictionCol='rawPrediction', \n",
    "            labelCol=TARGET\n",
    "        )\n",
    "        \n",
    "        return evaluator\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_hyperparams(cvModel):\n",
    "        import re\n",
    "\n",
    "        hyperparams = cvModel.getEstimatorParamMaps()[ np.argmax(cvModel.avgMetrics) ]\n",
    "        hyper_dict = {}\n",
    "\n",
    "        for i in range(len(hyperparams.items())):\n",
    "            hyper_name = re.search(\"name='(.+?)'\", str([x for x in hyperparams.items()][i])).group(1)\n",
    "            hyper_value = [x for x in hyperparams.items()][i][1]\n",
    "\n",
    "            hyper_dict[hyper_name]= hyper_value\n",
    "\n",
    "        print(hyper_dict)\n",
    "    \n",
    "        return hyper_dict\n",
    "    \n",
    "    def evaluate_cv_model(self, test_train_data):\n",
    "        import time\n",
    "\n",
    "        # Start the Timer\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_data, test_data = test_train_data.randomSplit([0.7, 0.3], seed=123) \n",
    "\n",
    "        # Fit the Model\n",
    "        print('Build Data Transformer')\n",
    "        data_transformer = self.pipeline.fit(train_data)\n",
    "\n",
    "        print('Transform Train Data + Fit CV Model')\n",
    "        cvModel = self.cvModel.setParallelism(CORES).fit(data_transformer.transform(train_data))\n",
    "\n",
    "        print('Transform Test Data')\n",
    "        data_train = data_transformer.transform(test_data)\n",
    "\n",
    "        print('Evaluate Model Against Test Data')\n",
    "        self.cv_predictions = cvModel.transform(data_train)\n",
    "\n",
    "        print('Store Results')\n",
    "        \n",
    "        self.results.cv_area_under_roc = self.evaluator.evaluate(\n",
    "            self.cv_predictions, \n",
    "            {self.evaluator.metricName: 'areaUnderROC'}\n",
    "        )\n",
    "        self.results.cv_area_under_pr = self.evaluator.evaluate(\n",
    "            self.cv_predictions, \n",
    "            {self.evaluator.metricName: 'areaUnderPR'}\n",
    "        )\n",
    "\n",
    "        # End Timer\n",
    "        self.results.cv_elapsed_time = round((time.time() - start_time), 2)\n",
    "\n",
    "        # Random Forest doesn't have coefficients\n",
    "        if self.model_type in (self.logistic, self.svm):\n",
    "            self.results.cv_best_coefficients = cvModel.bestModel.coefficients\n",
    "            \n",
    "        self.results.cv_best_hyperparameters = self.extract_hyperparams(cvModel)\n",
    "        \n",
    "    def evaluate_val_model(self, test_train_data, validation_data):\n",
    "        import time\n",
    "\n",
    "        # Start the Timer\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print('Build Data Transformer')\n",
    "        data_transformer = self.pipeline.fit(test_train_data)\n",
    "\n",
    "        print('Transform TestTrain Data + Fit Val Model')\n",
    "        valModel = self.valModel.fit(data_transformer.transform(test_train_data))\n",
    "        \n",
    "        print('Transform Validation Data')\n",
    "        data_train = data_transformer.transform(validation_data)\n",
    "\n",
    "        print('Evaluate Model Against Validation Data')\n",
    "        self.val_predictions = valModel.transform(data_train)\n",
    "        \n",
    "        print('Store Results')\n",
    "        \n",
    "        self.results.val_area_under_roc = self.evaluator.evaluate(\n",
    "            self.val_predictions, \n",
    "            {self.evaluator.metricName: 'areaUnderROC'}\n",
    "        )\n",
    "        self.results.val_area_under_pr = self.evaluator.evaluate(\n",
    "            self.val_predictions, \n",
    "            {self.evaluator.metricName: 'areaUnderPR'}\n",
    "        )\n",
    "\n",
    "        # End Timer\n",
    "        self.results.val_elapsed_time = round((time.time() - start_time), 2)\n",
    "\n",
    "        # Random Forest doesn't have coefficients\n",
    "        if self.model_type in (self.logistic, self.svm):\n",
    "            self.results.val_best_coefficients = valModel.coefficients\n",
    "            \n",
    "        self.results.val_true_positive = test_model.val_predictions.where((F.col('Won') == 1) & (F.col('prediction') == 1)).count()\n",
    "        self.results.val_false_negative = test_model.val_predictions.where((F.col('Won') == 1) & (F.col('prediction') == 0)).count()\n",
    "        self.results.val_false_positive = test_model.val_predictions.where((F.col('Won') == 0) & (F.col('prediction') == 1)).count()\n",
    "        self.results.val_true_negative = test_model.val_predictions.where((F.col('Won') == 0) & (F.col('prediction') == 0)).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMModel(Model):\n",
    "\n",
    "    def __init__(self, list_features):\n",
    "        Model.__init__(\n",
    "            self, \n",
    "            list_features = list_features, \n",
    "            model_type = 'Support Vector Machine'\n",
    "        )\n",
    "        \n",
    "    def build_cv_model(self):\n",
    "        import pyspark.ml.evaluation as ev\n",
    "        from pyspark.ml.classification import LinearSVC\n",
    "        import pyspark.ml.tuning as tune\n",
    "\n",
    "        print('Build CVModel: SVM')\n",
    "\n",
    "        svm = LinearSVC(featuresCol = FEATURES, labelCol=TARGET)\n",
    "\n",
    "        grid = tune.ParamGridBuilder() \\\n",
    "                    .addGrid(svm.aggregationDepth, [3, 5, 10]) \\\n",
    "                    .addGrid(svm.maxIter, [10, 20, 50]) \\\n",
    "                    .build()\n",
    "\n",
    "        self.cvModel = tune.CrossValidator( \n",
    "            estimator=svm, \n",
    "            estimatorParamMaps=grid, \n",
    "            evaluator=self.evaluator,\n",
    "            numFolds=5\n",
    "        )\n",
    "    \n",
    "    def build_val_model(self):\n",
    "        from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "        print('Build ValModel: SVM')\n",
    "\n",
    "        self.valModel = LinearSVC(\n",
    "            featuresCol = FEATURES, \n",
    "            labelCol=TARGET, \n",
    "            **self.results.cv_best_hyperparameters\n",
    "        )\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestModel(Model):\n",
    "\n",
    "    def __init__(self, list_features):\n",
    "        Model.__init__(\n",
    "            self, \n",
    "            list_features = list_features, \n",
    "            model_type = 'Random Forest'\n",
    "        )\n",
    "        \n",
    "    def build_cv_model(self):\n",
    "        from pyspark.ml.classification import RandomForestClassifier\n",
    "        import pyspark.ml.tuning as tune\n",
    "\n",
    "        print('Build CVModel: Random Forest')\n",
    "\n",
    "        random_forest = RandomForestClassifier(featuresCol = FEATURES, labelCol=TARGET)\n",
    "\n",
    "        grid = tune.ParamGridBuilder() \\\n",
    "            .addGrid(random_forest.maxBins, [2, 3]) \\\n",
    "            .addGrid(random_forest.maxDepth, [3, 5]) \\\n",
    "            .addGrid(random_forest.numTrees, [100, 500]) \\\n",
    "            .build()\n",
    "\n",
    "        self.cvModel = tune.CrossValidator( \n",
    "            estimator=random_forest, \n",
    "            estimatorParamMaps=grid, \n",
    "            evaluator=self.evaluator,\n",
    "            numFolds=5\n",
    "        )\n",
    "    \n",
    "    def build_val_model(self):\n",
    "        from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "        print('Build ValModel: Random Forest')\n",
    "\n",
    "        self.valModel = RandomForestClassifier(\n",
    "            featuresCol = FEATURES, \n",
    "            labelCol=TARGET, \n",
    "            **self.results.cv_best_hyperparameters\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticModel(Model):\n",
    "    \n",
    "    def __init__(self, list_features):\n",
    "        \n",
    "        Model.__init__(\n",
    "            self, \n",
    "            list_features = list_features, \n",
    "            model_type = 'Logistic'\n",
    "        )\n",
    "        \n",
    "    def build_cv_model(self):\n",
    "        from pyspark.ml.classification import LogisticRegression\n",
    "        import pyspark.ml.tuning as tune\n",
    "\n",
    "        print('Build CVModel: Logistic Regression')\n",
    "\n",
    "        logistic = LogisticRegression(featuresCol = FEATURES, labelCol=TARGET)\n",
    "\n",
    "        grid = tune.ParamGridBuilder() \\\n",
    "            .addGrid(logistic.maxIter, [10, 20]) \\\n",
    "            .addGrid(logistic.regParam, [0.1, 0.5]) \\\n",
    "            .build()\n",
    "\n",
    "        self.cvModel = tune.CrossValidator( \n",
    "            estimator=logistic, \n",
    "            estimatorParamMaps=grid, \n",
    "            evaluator=self.evaluator,\n",
    "            numFolds=5\n",
    "        )\n",
    "    \n",
    "    def build_val_model(self):\n",
    "        from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "        print('Build ValModel: Logistic Regression')\n",
    "\n",
    "        self.valModel = LogisticRegression(\n",
    "            featuresCol = FEATURES, \n",
    "            labelCol=TARGET, \n",
    "            **self.results.cv_best_hyperparameters\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/project/ds5559/group2nba/stacked_data/NBA_PBP_2018-19.csv']\n"
     ]
    }
   ],
   "source": [
    "train_files = [\n",
    "#     'NBA_PBP_2015-16.csv',\n",
    "#     'NBA_PBP_2016-17.csv',\n",
    "#     'NBA_PBP_2017-18.csv',\n",
    "    'NBA_PBP_2018-19.csv'\n",
    "]\n",
    "\n",
    "validation_file = 'NBA_PBP_2019-20.csv'\n",
    "\n",
    "# Read in all Train_Files\n",
    "\n",
    "file_list = []\n",
    "for item in train_files:\n",
    "    file_list.append(PATH_STACKED + item)\n",
    "    \n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_file(full_file_name):\n",
    "\n",
    "    df = spark.read \\\n",
    "        .format('csv') \\\n",
    "        .option('header', True) \\\n",
    "        .schema(schema) \\\n",
    "        .load(full_file_name)\n",
    "\n",
    "#     display(df.count())\n",
    "#     display(df.printSchema())\n",
    "#     display(df.head(2))\n",
    "    \n",
    "    return df\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "df = spark.read.csv(file_list)\n",
    "\n",
    "# test_train = 'NBA_PBP_2015-16.csv'\n",
    "validation = 'NBA_PBP_2019-20.csv'\n",
    "\n",
    "# # Load in your data - Can append more files to test_train if you want\n",
    "# #   by extending the 'read_in_files' with ',' between full file names\n",
    "test_train_df = read_in_file(file_list)\n",
    "validation_df = read_in_file(join(PATH_STACKED, validation))\n",
    "\n",
    "\n",
    "# test_train_df = test_train_df.where(F.col('SecLeftTotal') <= 300)\n",
    "# validation_df = validation_df.where(F.col('SecLeftTotal') <= 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results):\n",
    "    from os.path import exists\n",
    "\n",
    "    results_df = pd.DataFrame(data=[results])\n",
    "\n",
    "    file_exists = exists(RESULTS_FILE)\n",
    "    if file_exists:\n",
    "        results_df.to_csv(RESULTS_FILE, mode='a', index=False, header=False, sep=\"|\")\n",
    "    else:\n",
    "        results_df.to_csv(RESULTS_FILE, mode='w', index=False, header=True, sep=\"|\")\n",
    "\n",
    "def run_model(test_model):\n",
    "\n",
    "    # Run Cross Validation (Find Best Hyperparameters)\n",
    "    test_model.build_cv_model()\n",
    "    test_model.evaluate_cv_model(test_train_df)\n",
    "\n",
    "    # Run Model Validation\n",
    "    test_model.build_val_model()\n",
    "    test_model.evaluate_val_model(test_train_df, validation_df)\n",
    "\n",
    "    # Save the Results\n",
    "    save_results(test_model.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Model\n",
      "build the pipeline\n",
      "Build CVModel: SVM\n",
      "Build Data Transformer\n",
      "Transform Train Data + Fit CV Model\n"
     ]
    }
   ],
   "source": [
    "#   'HasPossession', 'assist_team_cnt', 'assist_opponent_cnt', 'turnover_team_cnt'\n",
    "# , 'turnover_opponent_cnt', 'block_team_cnt', 'block_opponent_cnt'\n",
    "# , 'foul_team_cnt', 'foul_opponent_cnt', 'rebound_team_cnt', 'rebound_opponent_cnt'\n",
    "# , 'shotOnGoal_team_cnt', 'shotOnGoal_opponent_cnt', 'freeThrow_team_cnt'\n",
    "# , 'freeThrow_opponent_cnt'\n",
    "# , 'SecLeftTotalInverseTimesScoreDiff'\n",
    "# , 'assist_diff', 'turnover_diff', 'block_diff', 'foul_diff', 'rebound_diff'\n",
    "# , 'shotOnGoal_diff', 'freeThrow_diff'\n",
    "# list_features = ['ScoreDiff']\n",
    "\n",
    "# List of Features to test (List is Above)\n",
    "list_features = ['assist_diff', 'turnover_diff', 'block_diff', 'foul_diff', 'rebound_diff', 'shotOnGoal_diff', 'freeThrow_diff']\n",
    "\n",
    "test_train_df = read_in_file(file_list)\n",
    "validation_df = read_in_file(join(PATH_STACKED, validation))\n",
    "\n",
    "# Any Modifications to the Data you want to make\n",
    "test_train_df = test_train_df.where(F.col('Quarter') == 4)\n",
    "validation_df = validation_df.where(F.col('Quarter') == 4)\n",
    "\n",
    "test_model = SVMModel(list_features)\n",
    "test_model.results.special_description = 'Quarter = 4'\n",
    "run_model(test_model)\n",
    "\n",
    "test_model = LogisticModel(list_features)\n",
    "test_model.results.special_description = 'Quarter = 4'\n",
    "run_model(test_model)\n",
    "\n",
    "# test_model = RandomForestModel(list_features)\n",
    "# test_model.results.special_description = 'Quarter = 4'\n",
    "# run_model(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>list_features</th>\n",
       "      <th>date_time_run</th>\n",
       "      <th>user</th>\n",
       "      <th>special_description</th>\n",
       "      <th>cv_elapsed_time</th>\n",
       "      <th>cv_area_under_roc</th>\n",
       "      <th>cv_area_under_pr</th>\n",
       "      <th>cv_best_coefficients</th>\n",
       "      <th>cv_best_hyperparameters</th>\n",
       "      <th>val_elapsed_time</th>\n",
       "      <th>val_area_under_roc</th>\n",
       "      <th>val_area_under_pr</th>\n",
       "      <th>val_best_coefficients</th>\n",
       "      <th>val_true_positive</th>\n",
       "      <th>val_true_negative</th>\n",
       "      <th>val_false_positive</th>\n",
       "      <th>val_false_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['assist_diff', 'turnover_diff', 'block_diff',...</td>\n",
       "      <td>04/20/2022 12:51:28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quarter &gt;= 3</td>\n",
       "      <td>102.19</td>\n",
       "      <td>0.829695</td>\n",
       "      <td>0.828194</td>\n",
       "      <td>[ 0.5812116  -0.344193   -0.22327406  0.035643...</td>\n",
       "      <td>{'maxIter': 20, 'regParam': 0.1}</td>\n",
       "      <td>22.46</td>\n",
       "      <td>0.786536</td>\n",
       "      <td>0.777428</td>\n",
       "      <td>[ 0.58121907 -0.34495717 -0.22373361  0.034718...</td>\n",
       "      <td>195987</td>\n",
       "      <td>195987</td>\n",
       "      <td>78475</td>\n",
       "      <td>78475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['ScoreDiff', 'SecLeftTotalInverseTimesScoreDi...</td>\n",
       "      <td>04/20/2022 12:52:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quarter &gt;= 3</td>\n",
       "      <td>91.50</td>\n",
       "      <td>0.910001</td>\n",
       "      <td>0.910292</td>\n",
       "      <td>[0.449166   0.06199055]</td>\n",
       "      <td>{'maxIter': 20, 'regParam': 0.5}</td>\n",
       "      <td>18.46</td>\n",
       "      <td>0.901117</td>\n",
       "      <td>0.901426</td>\n",
       "      <td>[0.44929998 0.0619288 ]</td>\n",
       "      <td>219873</td>\n",
       "      <td>229309</td>\n",
       "      <td>45153</td>\n",
       "      <td>54589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>['assist_diff', 'turnover_diff', 'block_diff',...</td>\n",
       "      <td>04/20/2022 12:56:25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quarter &gt;= 4</td>\n",
       "      <td>339.56</td>\n",
       "      <td>0.862297</td>\n",
       "      <td>0.863474</td>\n",
       "      <td>[ 0.75415664 -1.36413206 -0.20948062  0.053488...</td>\n",
       "      <td>{'aggregationDepth': 10, 'maxIter': 50}</td>\n",
       "      <td>25.43</td>\n",
       "      <td>0.820415</td>\n",
       "      <td>0.813079</td>\n",
       "      <td>[ 0.75870619 -1.36246121 -0.20495591  0.059093...</td>\n",
       "      <td>106313</td>\n",
       "      <td>106313</td>\n",
       "      <td>36806</td>\n",
       "      <td>36806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>['ScoreDiff', 'SecLeftTotalInverseTimesScoreDi...</td>\n",
       "      <td>04/20/2022 12:56:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quarter &gt;= 4</td>\n",
       "      <td>389.04</td>\n",
       "      <td>0.953682</td>\n",
       "      <td>0.955739</td>\n",
       "      <td>[ 2.10062818 24.57609777]</td>\n",
       "      <td>{'aggregationDepth': 5, 'maxIter': 20}</td>\n",
       "      <td>20.29</td>\n",
       "      <td>0.947664</td>\n",
       "      <td>0.949794</td>\n",
       "      <td>[ 2.21227477 20.56390867]</td>\n",
       "      <td>120800</td>\n",
       "      <td>125976</td>\n",
       "      <td>17143</td>\n",
       "      <td>22319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['assist_diff', 'turnover_diff', 'block_diff',...</td>\n",
       "      <td>04/20/2022 13:02:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quarter &gt;= 4</td>\n",
       "      <td>71.83</td>\n",
       "      <td>0.847070</td>\n",
       "      <td>0.845680</td>\n",
       "      <td>[ 0.61398379 -0.36178735 -0.23379962  0.028837...</td>\n",
       "      <td>{'maxIter': 20, 'regParam': 0.1}</td>\n",
       "      <td>17.55</td>\n",
       "      <td>0.801229</td>\n",
       "      <td>0.793778</td>\n",
       "      <td>[ 0.61627394 -0.3620753  -0.23038445  0.030426...</td>\n",
       "      <td>103500</td>\n",
       "      <td>103500</td>\n",
       "      <td>39619</td>\n",
       "      <td>39619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['ScoreDiff', 'SecLeftTotalInverseTimesScoreDi...</td>\n",
       "      <td>04/20/2022 13:03:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quarter &gt;= 4</td>\n",
       "      <td>67.53</td>\n",
       "      <td>0.948890</td>\n",
       "      <td>0.950640</td>\n",
       "      <td>[0.48378834 0.08352543]</td>\n",
       "      <td>{'maxIter': 10, 'regParam': 0.5}</td>\n",
       "      <td>16.05</td>\n",
       "      <td>0.941905</td>\n",
       "      <td>0.943440</td>\n",
       "      <td>[0.48369291 0.08341884]</td>\n",
       "      <td>120800</td>\n",
       "      <td>125976</td>\n",
       "      <td>17143</td>\n",
       "      <td>22319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>['assist_diff', 'turnover_diff', 'block_diff',...</td>\n",
       "      <td>04/20/2022 13:06:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quarter &gt;= 5</td>\n",
       "      <td>208.17</td>\n",
       "      <td>0.650696</td>\n",
       "      <td>0.599396</td>\n",
       "      <td>[-0.05058997 -1.86745284 -0.05936869  0.189597...</td>\n",
       "      <td>{'aggregationDepth': 5, 'maxIter': 50}</td>\n",
       "      <td>17.76</td>\n",
       "      <td>0.640618</td>\n",
       "      <td>0.629317</td>\n",
       "      <td>[ 0.00450144 -1.78683662 -0.08343831  0.228016...</td>\n",
       "      <td>2636</td>\n",
       "      <td>2636</td>\n",
       "      <td>1876</td>\n",
       "      <td>1876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['assist_diff', 'turnover_diff', 'block_diff',...</td>\n",
       "      <td>04/20/2022 13:10:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quarter &gt;= 5</td>\n",
       "      <td>42.27</td>\n",
       "      <td>0.615654</td>\n",
       "      <td>0.607782</td>\n",
       "      <td>[ 0.03786394 -0.24566945 -0.11224499 -0.027887...</td>\n",
       "      <td>{'maxIter': 20, 'regParam': 0.1}</td>\n",
       "      <td>7.46</td>\n",
       "      <td>0.625692</td>\n",
       "      <td>0.596167</td>\n",
       "      <td>[ 0.04709074 -0.23582563 -0.11578692 -0.025220...</td>\n",
       "      <td>2679</td>\n",
       "      <td>2679</td>\n",
       "      <td>1833</td>\n",
       "      <td>1833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>['ScoreDiff', 'SecLeftTotalInverseTimesScoreDi...</td>\n",
       "      <td>04/20/2022 13:06:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quarter &gt;= 5</td>\n",
       "      <td>268.12</td>\n",
       "      <td>0.815262</td>\n",
       "      <td>0.823383</td>\n",
       "      <td>[1.00906297 2.46910011]</td>\n",
       "      <td>{'aggregationDepth': 5, 'maxIter': 50}</td>\n",
       "      <td>24.03</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[-0. -0.]</td>\n",
       "      <td>0</td>\n",
       "      <td>4512</td>\n",
       "      <td>0</td>\n",
       "      <td>4512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>['ScoreDiff', 'SecLeftTotalInverseTimesScoreDi...</td>\n",
       "      <td>04/20/2022 13:11:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quarter &gt;= 5</td>\n",
       "      <td>38.98</td>\n",
       "      <td>0.811787</td>\n",
       "      <td>0.817189</td>\n",
       "      <td>[0.73565047 0.32991269]</td>\n",
       "      <td>{'maxIter': 10, 'regParam': 0.1}</td>\n",
       "      <td>9.12</td>\n",
       "      <td>0.875325</td>\n",
       "      <td>0.880782</td>\n",
       "      <td>[0.74147983 0.33760455]</td>\n",
       "      <td>3113</td>\n",
       "      <td>3833</td>\n",
       "      <td>679</td>\n",
       "      <td>1399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model_type                                      list_features  \\\n",
       "57                Logistic  ['assist_diff', 'turnover_diff', 'block_diff',...   \n",
       "58                Logistic  ['ScoreDiff', 'SecLeftTotalInverseTimesScoreDi...   \n",
       "59  Support Vector Machine  ['assist_diff', 'turnover_diff', 'block_diff',...   \n",
       "60  Support Vector Machine  ['ScoreDiff', 'SecLeftTotalInverseTimesScoreDi...   \n",
       "61                Logistic  ['assist_diff', 'turnover_diff', 'block_diff',...   \n",
       "62                Logistic  ['ScoreDiff', 'SecLeftTotalInverseTimesScoreDi...   \n",
       "63  Support Vector Machine  ['assist_diff', 'turnover_diff', 'block_diff',...   \n",
       "64                Logistic  ['assist_diff', 'turnover_diff', 'block_diff',...   \n",
       "65  Support Vector Machine  ['ScoreDiff', 'SecLeftTotalInverseTimesScoreDi...   \n",
       "66                Logistic  ['ScoreDiff', 'SecLeftTotalInverseTimesScoreDi...   \n",
       "\n",
       "          date_time_run  user special_description  cv_elapsed_time  \\\n",
       "57  04/20/2022 12:51:28   NaN        Quarter >= 3           102.19   \n",
       "58  04/20/2022 12:52:07   NaN        Quarter >= 3            91.50   \n",
       "59  04/20/2022 12:56:25   NaN        Quarter >= 4           339.56   \n",
       "60  04/20/2022 12:56:41   NaN        Quarter >= 4           389.04   \n",
       "61  04/20/2022 13:02:43   NaN        Quarter >= 4            71.83   \n",
       "62  04/20/2022 13:03:42   NaN        Quarter >= 4            67.53   \n",
       "63  04/20/2022 13:06:53   NaN        Quarter >= 5           208.17   \n",
       "64  04/20/2022 13:10:45   NaN        Quarter >= 5            42.27   \n",
       "65  04/20/2022 13:06:43   NaN        Quarter >= 5           268.12   \n",
       "66  04/20/2022 13:11:42   NaN        Quarter >= 5            38.98   \n",
       "\n",
       "    cv_area_under_roc  cv_area_under_pr  \\\n",
       "57           0.829695          0.828194   \n",
       "58           0.910001          0.910292   \n",
       "59           0.862297          0.863474   \n",
       "60           0.953682          0.955739   \n",
       "61           0.847070          0.845680   \n",
       "62           0.948890          0.950640   \n",
       "63           0.650696          0.599396   \n",
       "64           0.615654          0.607782   \n",
       "65           0.815262          0.823383   \n",
       "66           0.811787          0.817189   \n",
       "\n",
       "                                 cv_best_coefficients  \\\n",
       "57  [ 0.5812116  -0.344193   -0.22327406  0.035643...   \n",
       "58                            [0.449166   0.06199055]   \n",
       "59  [ 0.75415664 -1.36413206 -0.20948062  0.053488...   \n",
       "60                          [ 2.10062818 24.57609777]   \n",
       "61  [ 0.61398379 -0.36178735 -0.23379962  0.028837...   \n",
       "62                            [0.48378834 0.08352543]   \n",
       "63  [-0.05058997 -1.86745284 -0.05936869  0.189597...   \n",
       "64  [ 0.03786394 -0.24566945 -0.11224499 -0.027887...   \n",
       "65                            [1.00906297 2.46910011]   \n",
       "66                            [0.73565047 0.32991269]   \n",
       "\n",
       "                    cv_best_hyperparameters  val_elapsed_time  \\\n",
       "57         {'maxIter': 20, 'regParam': 0.1}             22.46   \n",
       "58         {'maxIter': 20, 'regParam': 0.5}             18.46   \n",
       "59  {'aggregationDepth': 10, 'maxIter': 50}             25.43   \n",
       "60   {'aggregationDepth': 5, 'maxIter': 20}             20.29   \n",
       "61         {'maxIter': 20, 'regParam': 0.1}             17.55   \n",
       "62         {'maxIter': 10, 'regParam': 0.5}             16.05   \n",
       "63   {'aggregationDepth': 5, 'maxIter': 50}             17.76   \n",
       "64         {'maxIter': 20, 'regParam': 0.1}              7.46   \n",
       "65   {'aggregationDepth': 5, 'maxIter': 50}             24.03   \n",
       "66         {'maxIter': 10, 'regParam': 0.1}              9.12   \n",
       "\n",
       "    val_area_under_roc  val_area_under_pr  \\\n",
       "57            0.786536           0.777428   \n",
       "58            0.901117           0.901426   \n",
       "59            0.820415           0.813079   \n",
       "60            0.947664           0.949794   \n",
       "61            0.801229           0.793778   \n",
       "62            0.941905           0.943440   \n",
       "63            0.640618           0.629317   \n",
       "64            0.625692           0.596167   \n",
       "65            0.500000           0.500000   \n",
       "66            0.875325           0.880782   \n",
       "\n",
       "                                val_best_coefficients  val_true_positive  \\\n",
       "57  [ 0.58121907 -0.34495717 -0.22373361  0.034718...             195987   \n",
       "58                            [0.44929998 0.0619288 ]             219873   \n",
       "59  [ 0.75870619 -1.36246121 -0.20495591  0.059093...             106313   \n",
       "60                          [ 2.21227477 20.56390867]             120800   \n",
       "61  [ 0.61627394 -0.3620753  -0.23038445  0.030426...             103500   \n",
       "62                            [0.48369291 0.08341884]             120800   \n",
       "63  [ 0.00450144 -1.78683662 -0.08343831  0.228016...               2636   \n",
       "64  [ 0.04709074 -0.23582563 -0.11578692 -0.025220...               2679   \n",
       "65                                          [-0. -0.]                  0   \n",
       "66                            [0.74147983 0.33760455]               3113   \n",
       "\n",
       "    val_true_negative  val_false_positive  val_false_negative  \n",
       "57             195987               78475               78475  \n",
       "58             229309               45153               54589  \n",
       "59             106313               36806               36806  \n",
       "60             125976               17143               22319  \n",
       "61             103500               39619               39619  \n",
       "62             125976               17143               22319  \n",
       "63               2636                1876                1876  \n",
       "64               2679                1833                1833  \n",
       "65               4512                   0                4512  \n",
       "66               3833                 679                1399  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_df = pd.read_csv(RESULTS_FILE, sep='|')\n",
    "view_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=8, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=6, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=3, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=3, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=4, prediction=1.0),\n",
       " Row(Won=0, ScoreDiff=5, prediction=1.0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "test_model.val_predictions.where((F.col('Won') != 1) & (F.col('ScoreDiff') > 1)).select('Won', 'ScoreDiff', 'prediction').take(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
