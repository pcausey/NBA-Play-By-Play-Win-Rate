{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "import regex as re\n",
    "\n",
    "from IPython.display import display\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier, LinearSVC, LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('group2nba') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_main = '/project/ds5559/group2nba'\n",
    "\n",
    "T = TypeVar('T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML_CV():\n",
    "    __slots__: List[str] = [\n",
    "          'Model'\n",
    "        , 'TestParameters'\n",
    "        , 'BestParameters'\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, model: T, test_params: Callable, best_params: Callable):\n",
    "        self.Model = model\n",
    "        self.TestParameters = test_params\n",
    "        self.BestParameters = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDS: Dict[str, T] = {\n",
    "      'Date': StringType\n",
    "    , 'HomeTeam': StringType\n",
    "    , 'AwayTeam': StringType\n",
    "    , 'Team': StringType\n",
    "    , 'Year': IntegerType\n",
    "    , 'Won': IntegerType\n",
    "    , 'ScoreDiff': IntegerType\n",
    "    , 'Quarter': IntegerType\n",
    "    , 'ScoreDiff': IntegerType\n",
    "    , 'SecLeftTotal': IntegerType\n",
    "    , 'LogSecLeftTotal': DoubleType\n",
    "    , 'SecLeftTotalInverse': DoubleType\n",
    "    , 'HasPossession': IntegerType\n",
    "    , 'assist_team_cnt': LongType\n",
    "    , 'assist_opponent_cnt': LongType\n",
    "    , 'turnover_team_cnt': LongType\n",
    "    , 'turnover_opponent_cnt': LongType\n",
    "    , 'block_team_cnt': LongType\n",
    "    , 'block_opponent_cnt': LongType\n",
    "    , 'foul_team_cnt': LongType\n",
    "    , 'foul_opponent_cnt': LongType\n",
    "    , 'rebound_team_cnt': LongType\n",
    "    , 'rebound_opponent_cnt': LongType\n",
    "    , 'shotOnGoal_team_cnt': LongType\n",
    "    , 'shotOnGoal_opponent_cnt': LongType\n",
    "    , 'freeThrow_team_cnt': LongType\n",
    "    , 'freeThrow_opponent_cnt': LongType\n",
    "    , 'SecLeftTotalInverseTimesScoreDiff': DoubleType\n",
    "    , 'assist_diff': IntegerType\n",
    "    , 'turnover_diff': IntegerType\n",
    "    , 'block_diff': IntegerType\n",
    "    , 'foul_diff': IntegerType\n",
    "    , 'rebound_diff': IntegerType\n",
    "    , 'shotOnGoal_diff': IntegerType\n",
    "    , 'freeThrow_diff': IntegerType\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT\n",
    "MODEL_FEATURES = [\n",
    "      'SecLeftTotal'\n",
    "    , 'ScoreDiff'\n",
    "    , 'HasPossession'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validate(df: DataFrame, ml_method: str, features: List[str], k_folds: int = 10) -> DataFrame:\n",
    "#     '''...'''\n",
    "#     # retrieve the necessary information to cross validate the model type\n",
    "#     method = DICT_ML[ml_method]\n",
    "#     \n",
    "#     # create pipeline\n",
    "#     pipeline = Pipeline(stages = [\n",
    "#           VectorAssembler(inputCols = features, outputCol = 'features')\n",
    "#         , method.Model(featuresCol = 'features', labelCol = 'Won')\n",
    "#     ])\n",
    "#     \n",
    "#     # define the hyperparmeters to test\n",
    "#     param_grid = method.TestParameters(pipeline.getStages()[1])\n",
    "#     \n",
    "#     # classification method\n",
    "#     classifier = BinaryClassificationEvaluator(\n",
    "#           metricName = 'areaUnderROC'\n",
    "#         , rawPredictionCol = 'rawPrediction'\n",
    "#         , labelCol = 'Won'\n",
    "#     )\n",
    "#     \n",
    "#     # do cross validation\n",
    "#     cv_model = CrossValidator(\n",
    "#           estimator = pipeline\n",
    "#         , estimatorParamMaps = param_grid\n",
    "#         , evaluator = classifier\n",
    "#         , numFolds = k_folds\n",
    "#     ).setParallelism(k_folds).fit(df)\n",
    "# \n",
    "#     # return results as pandas dataframe\n",
    "#     return pd.DataFrame({\n",
    "#           'Method': [ml_method]\n",
    "#         , 'ROC': [cv_model.avgMetrics[0]]\n",
    "#         , 'HyperParameters': [json.dumps(method.BestParameters(cv_model.bestModel.stages[1]))]\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6078776"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- HomeTeam: string (nullable = true)\n",
      " |-- AwayTeam: string (nullable = true)\n",
      " |-- Team: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Won: integer (nullable = true)\n",
      " |-- ScoreDiff: integer (nullable = true)\n",
      " |-- Quarter: integer (nullable = true)\n",
      " |-- SecLeftTotal: integer (nullable = true)\n",
      " |-- LogSecLeftTotal: double (nullable = true)\n",
      " |-- SecLeftTotalInverse: double (nullable = true)\n",
      " |-- HasPossession: integer (nullable = true)\n",
      " |-- assist_team_cnt: long (nullable = true)\n",
      " |-- assist_opponent_cnt: long (nullable = true)\n",
      " |-- turnover_team_cnt: long (nullable = true)\n",
      " |-- turnover_opponent_cnt: long (nullable = true)\n",
      " |-- block_team_cnt: long (nullable = true)\n",
      " |-- block_opponent_cnt: long (nullable = true)\n",
      " |-- foul_team_cnt: long (nullable = true)\n",
      " |-- foul_opponent_cnt: long (nullable = true)\n",
      " |-- rebound_team_cnt: long (nullable = true)\n",
      " |-- rebound_opponent_cnt: long (nullable = true)\n",
      " |-- shotOnGoal_team_cnt: long (nullable = true)\n",
      " |-- shotOnGoal_opponent_cnt: long (nullable = true)\n",
      " |-- freeThrow_team_cnt: long (nullable = true)\n",
      " |-- freeThrow_opponent_cnt: long (nullable = true)\n",
      " |-- SecLeftTotalInverseTimesScoreDiff: double (nullable = true)\n",
      " |-- assist_diff: integer (nullable = true)\n",
      " |-- turnover_diff: integer (nullable = true)\n",
      " |-- block_diff: integer (nullable = true)\n",
      " |-- foul_diff: integer (nullable = true)\n",
      " |-- rebound_diff: integer (nullable = true)\n",
      " |-- shotOnGoal_diff: integer (nullable = true)\n",
      " |-- freeThrow_diff: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Row(Date='December 22 2018', HomeTeam='WAS', AwayTeam='PHO', Team='PHO', Year=2018, Won=0, ScoreDiff=0, Quarter=1, SecLeftTotal=3761, LogSecLeftTotal=8.232706009860976, SecLeftTotalInverse=0.0002658160552897395, HasPossession=1, assist_team_cnt=0, assist_opponent_cnt=0, turnover_team_cnt=0, turnover_opponent_cnt=0, block_team_cnt=0, block_opponent_cnt=0, foul_team_cnt=0, foul_opponent_cnt=0, rebound_team_cnt=0, rebound_opponent_cnt=0, shotOnGoal_team_cnt=1, shotOnGoal_opponent_cnt=0, freeThrow_team_cnt=0, freeThrow_opponent_cnt=0, SecLeftTotalInverseTimesScoreDiff=0.0, assist_diff=0, turnover_diff=0, block_diff=0, foul_diff=0, rebound_diff=0, shotOnGoal_diff=1, freeThrow_diff=0),\n",
       " Row(Date='December 22 2018', HomeTeam='WAS', AwayTeam='PHO', Team='PHO', Year=2018, Won=0, ScoreDiff=0, Quarter=1, SecLeftTotal=3760, LogSecLeftTotal=8.232440158470336, SecLeftTotalInverse=0.00026588673225206064, HasPossession=0, assist_team_cnt=0, assist_opponent_cnt=0, turnover_team_cnt=0, turnover_opponent_cnt=0, block_team_cnt=0, block_opponent_cnt=0, foul_team_cnt=0, foul_opponent_cnt=0, rebound_team_cnt=0, rebound_opponent_cnt=1, shotOnGoal_team_cnt=1, shotOnGoal_opponent_cnt=0, freeThrow_team_cnt=0, freeThrow_opponent_cnt=0, SecLeftTotalInverseTimesScoreDiff=0.0, assist_diff=0, turnover_diff=0, block_diff=0, foul_diff=0, rebound_diff=-1, shotOnGoal_diff=1, freeThrow_diff=0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "schema_data = StructType([StructField(k, v()) for k, v in FIELDS.items()])\n",
    "\n",
    "df_train = spark.read \\\n",
    "    .format('csv') \\\n",
    "    .option('header', True) \\\n",
    "    .schema(schema_data) \\\n",
    "    .load(f'{path_main}/stacked_data/*')\n",
    "\n",
    "display(df_train.count())\n",
    "display(df_train.printSchema())\n",
    "display(df_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730846"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- HomeTeam: string (nullable = true)\n",
      " |-- AwayTeam: string (nullable = true)\n",
      " |-- Team: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Won: integer (nullable = true)\n",
      " |-- ScoreDiff: integer (nullable = true)\n",
      " |-- Quarter: integer (nullable = true)\n",
      " |-- SecLeftTotal: integer (nullable = true)\n",
      " |-- LogSecLeftTotal: double (nullable = true)\n",
      " |-- SecLeftTotalInverse: double (nullable = true)\n",
      " |-- HasPossession: integer (nullable = true)\n",
      " |-- assist_team_cnt: long (nullable = true)\n",
      " |-- assist_opponent_cnt: long (nullable = true)\n",
      " |-- turnover_team_cnt: long (nullable = true)\n",
      " |-- turnover_opponent_cnt: long (nullable = true)\n",
      " |-- block_team_cnt: long (nullable = true)\n",
      " |-- block_opponent_cnt: long (nullable = true)\n",
      " |-- foul_team_cnt: long (nullable = true)\n",
      " |-- foul_opponent_cnt: long (nullable = true)\n",
      " |-- rebound_team_cnt: long (nullable = true)\n",
      " |-- rebound_opponent_cnt: long (nullable = true)\n",
      " |-- shotOnGoal_team_cnt: long (nullable = true)\n",
      " |-- shotOnGoal_opponent_cnt: long (nullable = true)\n",
      " |-- freeThrow_team_cnt: long (nullable = true)\n",
      " |-- freeThrow_opponent_cnt: long (nullable = true)\n",
      " |-- SecLeftTotalInverseTimesScoreDiff: double (nullable = true)\n",
      " |-- assist_diff: integer (nullable = true)\n",
      " |-- turnover_diff: integer (nullable = true)\n",
      " |-- block_diff: integer (nullable = true)\n",
      " |-- foul_diff: integer (nullable = true)\n",
      " |-- rebound_diff: integer (nullable = true)\n",
      " |-- shotOnGoal_diff: integer (nullable = true)\n",
      " |-- freeThrow_diff: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Row(Date='December 22 2018', HomeTeam='WAS', AwayTeam='PHO', Team='PHO', Year=2018, Won=0, ScoreDiff=0, Quarter=6, SecLeftTotal=300, LogSecLeftTotal=5.707110264748875, SecLeftTotalInverse=0.0033222591362126247, HasPossession=1, assist_team_cnt=27, assist_opponent_cnt=38, turnover_team_cnt=15, turnover_opponent_cnt=22, block_team_cnt=5, block_opponent_cnt=6, foul_team_cnt=26, foul_opponent_cnt=23, rebound_team_cnt=59, rebound_opponent_cnt=57, shotOnGoal_team_cnt=105, shotOnGoal_opponent_cnt=101, freeThrow_team_cnt=32, freeThrow_opponent_cnt=22, SecLeftTotalInverseTimesScoreDiff=0.0, assist_diff=-11, turnover_diff=-7, block_diff=-1, foul_diff=3, rebound_diff=2, shotOnGoal_diff=4, freeThrow_diff=10),\n",
       " Row(Date='December 22 2018', HomeTeam='WAS', AwayTeam='PHO', Team='PHO', Year=2018, Won=0, ScoreDiff=0, Quarter=6, SecLeftTotal=300, LogSecLeftTotal=5.707110264748875, SecLeftTotalInverse=0.0033222591362126247, HasPossession=0, assist_team_cnt=27, assist_opponent_cnt=38, turnover_team_cnt=15, turnover_opponent_cnt=22, block_team_cnt=5, block_opponent_cnt=6, foul_team_cnt=26, foul_opponent_cnt=23, rebound_team_cnt=59, rebound_opponent_cnt=57, shotOnGoal_team_cnt=105, shotOnGoal_opponent_cnt=101, freeThrow_team_cnt=32, freeThrow_opponent_cnt=22, SecLeftTotalInverseTimesScoreDiff=0.0, assist_diff=-11, turnover_diff=-7, block_diff=-1, foul_diff=3, rebound_diff=2, shotOnGoal_diff=4, freeThrow_diff=10)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = df_train \\\n",
    "    .where(F.col('SecLeftTotal') <= 300)\n",
    "\n",
    "display(df_train.count())\n",
    "display(df_train.printSchema())\n",
    "display(df_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_cv = StructType([\n",
    "      StructField('Method', StringType())\n",
    "    , StructField('ROC', FloatType())\n",
    "    , StructField('HyperParameters', StringType())\n",
    "])\n",
    "\n",
    "cv_results = spark.createDataFrame({}, schema = schema_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cv_results = pd.concat([cv_results, cross_validate(df_train, 'GradientBoost', MODEL_FEATURES)])\n",
    "# '''...'''\n",
    "# # create pipeline\n",
    "# pipeline = Pipeline(stages = [\n",
    "#       VectorAssembler(inputCols = MODEL_FEATURES, outputCol = 'features')\n",
    "#     , GBTClassifier(featuresCol = 'features', labelCol = 'Won')\n",
    "# ])\n",
    "# \n",
    "# # define the hyperparmeters to test\n",
    "# param_grid = ParamGridBuilder() \\\n",
    "#     .addGrid(pipeline.getStages()[1].maxBins, [2, 3]) \\\n",
    "#     .addGrid(pipeline.getStages()[1].maxDepth, [3, 5, 10]) \\\n",
    "#     .build()\n",
    "# \n",
    "# # classification method\n",
    "# classifier = BinaryClassificationEvaluator(\n",
    "#       metricName = 'areaUnderROC'\n",
    "#     , rawPredictionCol = 'rawPrediction'\n",
    "#     , labelCol = 'Won'\n",
    "# )\n",
    "# \n",
    "# # do cross validation\n",
    "# cv_model = CrossValidator(\n",
    "#       estimator = pipeline\n",
    "#     , estimatorParamMaps = param_grid\n",
    "#     , evaluator = classifier\n",
    "#     , numFolds = 5\n",
    "# ).setParallelism(2).fit(df_train)\n",
    "# \n",
    "# # return results as a dataframe\n",
    "# cv_results = cv_results.union(spark.createDataFrame([(\n",
    "#       'GradientBoost'\n",
    "#     , cv_model.avgMetrics[0]\n",
    "#     , json.dumps({\n",
    "#           'maxBins': cv_model.bestModel.stages[1]._java_obj.getMaxBins()\n",
    "#         , 'maxDepth': cv_model.bestModel.stages[1]._java_obj.getMaxDepth()\n",
    "#       })\n",
    "# )], schema_cv))\n",
    "# cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_results = pd.concat([cv_results, cross_validate(df_train, 'LinearSVC', MODEL_FEATURES)])\n",
    "'''...'''\n",
    "# create pipeline\n",
    "pipeline = Pipeline(stages = [\n",
    "      VectorAssembler(inputCols = MODEL_FEATURES, outputCol = 'features')\n",
    "    , LinearSVC(featuresCol = 'features', labelCol = 'Won')\n",
    "])\n",
    "\n",
    "# define the hyperparmeters to test\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(pipeline.getStages()[1].aggregationDepth, [3, 5, 10]) \\\n",
    "    .addGrid(pipeline.getStages()[1].maxIter, [10, 20, 50]) \\\n",
    "    .build()\n",
    "\n",
    "# classification method\n",
    "classifier = BinaryClassificationEvaluator(\n",
    "      metricName = 'areaUnderROC'\n",
    "    , rawPredictionCol = 'rawPrediction'\n",
    "    , labelCol = 'Won'\n",
    ")\n",
    "\n",
    "# do cross validation\n",
    "cv_model = CrossValidator(\n",
    "      estimator = pipeline\n",
    "    , estimatorParamMaps = param_grid\n",
    "    , evaluator = classifier\n",
    "    , numFolds = 5\n",
    ").setParallelism(2).fit(df_train)\n",
    "\n",
    "# return results as a dataframe\n",
    "cv_results = cv_results.union(spark.createDataFrame([(\n",
    "      'LinearSVC'\n",
    "    , cv_model.avgMetrics[0]\n",
    "    , json.dumps({\n",
    "          'maxIter': cv_model.bestModel.stages[1].getMaxIter()\n",
    "        , 'regParam': cv_model.bestModel.stages[1].getRegParam()\n",
    "      })\n",
    ")], schema_cv))\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logist Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Method: string, ROC: float, HyperParameters: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv_results = pd.concat([cv_results, cross_validate(df_train, 'LogisticRegression', MODEL_FEATURES)])\n",
    "'''...'''\n",
    "# create pipeline\n",
    "pipeline = Pipeline(stages = [\n",
    "      VectorAssembler(inputCols = MODEL_FEATURES, outputCol = 'features')\n",
    "    , LogisticRegression(featuresCol = 'features', labelCol = 'Won')\n",
    "])\n",
    "\n",
    "# define the hyperparmeters to test\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(pipeline.getStages()[1].maxIter, [10, 20]) \\\n",
    "    .addGrid(pipeline.getStages()[1].regParam, [0.1, 0.5]) \\\n",
    "    .build()\n",
    "\n",
    "# classification method\n",
    "classifier = BinaryClassificationEvaluator(\n",
    "      metricName = 'areaUnderROC'\n",
    "    , rawPredictionCol = 'rawPrediction'\n",
    "    , labelCol = 'Won'\n",
    ")\n",
    "\n",
    "# do cross validation\n",
    "cv_model = CrossValidator(\n",
    "      estimator = pipeline\n",
    "    , estimatorParamMaps = param_grid\n",
    "    , evaluator = classifier\n",
    "    , numFolds = 5\n",
    ").setParallelism(2).fit(df_train)\n",
    "\n",
    "# return results as a dataframe\n",
    "cv_results = cv_results.union(spark.createDataFrame([(\n",
    "      'LogisticRegression'\n",
    "    , cv_model.avgMetrics[0]\n",
    "    , json.dumps({\n",
    "          'maxIter': cv_model.bestModel.stages[1].getMaxIter()\n",
    "        , 'regParam': cv_model.bestModel.stages[1].getRegParam()\n",
    "      })\n",
    ")], schema_cv))\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Method: string, ROC: float, HyperParameters: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv_results = pd.concat([cv_results, cross_validate(df_train, 'RandomForest', MODEL_FEATURES)])\n",
    "'''...'''\n",
    "# create pipeline\n",
    "pipeline = Pipeline(stages = [\n",
    "      VectorAssembler(inputCols = MODEL_FEATURES, outputCol = 'features')\n",
    "    , RandomForestClassifier(featuresCol = 'features', labelCol = 'Won')\n",
    "])\n",
    "\n",
    "# define the hyperparmeters to test\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(pipeline.getStages()[1].maxBins, [2, 3]) \\\n",
    "    .addGrid(pipeline.getStages()[1].maxDepth, [3, 5]) \\\n",
    "    .addGrid(pipeline.getStages()[1].numTrees, [100, 500]) \\\n",
    "    .build()\n",
    "\n",
    "# classification method\n",
    "classifier = BinaryClassificationEvaluator(\n",
    "      metricName = 'areaUnderROC'\n",
    "    , rawPredictionCol = 'rawPrediction'\n",
    "    , labelCol = 'Won'\n",
    ")\n",
    "\n",
    "# do cross validation\n",
    "cv_model = CrossValidator(\n",
    "      estimator = pipeline\n",
    "    , estimatorParamMaps = param_grid\n",
    "    , evaluator = classifier\n",
    "    , numFolds = 5\n",
    ").setParallelism(2).fit(df_train)\n",
    "\n",
    "# return results as a dataframe\n",
    "cv_results = cv_results.union(spark.createDataFrame([(\n",
    "      'RandomForest'\n",
    "    , cv_model.avgMetrics[0]\n",
    "    , json.dumps({\n",
    "          'maxBins': cv_model.bestModel.stages[1]._java_obj.getMaxBins()\n",
    "        , 'maxDepth': cv_model.bestModel.stages[1]._java_obj.getMaxDepth()\n",
    "        , 'numTrees': cv_model.bestModel.stages[1]._java_obj.getNumTrees()\n",
    "      })\n",
    ")], schema_cv))\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_write = f'{path_main}/models_cv'\n",
    "    \n",
    "cv_results.write.csv(f'{path_write}/cv_results_{len(os.listdir(path_write))}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110 Spark 3.1",
   "language": "python",
   "name": "ds5110_spark3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
